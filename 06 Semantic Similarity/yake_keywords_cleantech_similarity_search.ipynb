{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_titles = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks_embeddings.json')\n",
    "\n",
    "# Convert columns 'keyword_patentsberta_embedding', 'keyword_climatebert_embedding', 'keyword_bertforpatents_embedding' to numpy arrays\n",
    "df_keywords_titles['keyword_yake_patentsberta_embedding'] = df_keywords_titles['keyword_yake_patentsberta_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_titles['keyword_yake_climatebert_embedding'] = df_keywords_titles['keyword_yake_climatebert_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_titles['keyword_yake_bertforpatents_embedding'] = df_keywords_titles['keyword_yake_bertforpatents_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_claims = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_noun_chunks.json')\n",
    "\n",
    "# Convert columns 'keyword_yake_patentsberta_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_bertforpatents_embedding' to numpy arrays\n",
    "df_keywords_claims['keyword_yake_patentsberta_embedding'] = df_keywords_claims['keyword_yake_patentsberta_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_claims['keyword_yake_climatebert_embedding'] = df_keywords_claims['keyword_yake_climatebert_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_claims['keyword_yake_bertforpatents_embedding'] = df_keywords_claims['keyword_yake_bertforpatents_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out all keyword_yake_lemma for cpc_class_symbol = Y02W\n",
    "print(df_keywords_titles[df_keywords_titles['cpc_class_symbol'].progress_apply(lambda x: 'Y02W10/33' in x)][['keyword_yake_lemma', 'cpc_class_symbol']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search test to row with keyword = solar cells\n",
    "df_search_test_titles = df_keywords_titles[df_keywords_titles['keyword_yake_lemma'] == 'wind energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of df_search_test_titles\n",
    "df_search_test_titles.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_test_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean Distance - kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eucledian distance\n",
    "index_bertforpatents = faiss.IndexFlatL2(1024)   # build the index\n",
    "index_climatebert = faiss.IndexFlatL2(768)   # build the index\n",
    "index_patentsberta = faiss.IndexFlatL2(768)   # build the index\n",
    "\n",
    "# Add df_keywords_claims column 'keyword_yake_bertforpatents_embedding' to index\n",
    "index_bertforpatents.add(np.array(df_keywords_claims['keyword_yake_bertforpatents_embedding'].tolist()))\n",
    "index_climatebert.add(np.array(df_keywords_claims['keyword_yake_climatebert_embedding'].tolist()))\n",
    "index_patentsberta.add(np.array(df_keywords_claims['keyword_yake_patentsberta_embedding'].tolist()))\n",
    "\n",
    "query_vector_bertforpatents = np.array(df_search_test_titles['keyword_bertforpatents_embedding'][0]).reshape(1, -1)\n",
    "query_vector_climatebert = np.array(df_search_test_titles['keyword_climatebert_embedding'][0]).reshape(1, -1)\n",
    "query_vector_patentsberta = np.array(df_search_test_titles['keyword_patentsberta_embedding'][0]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "D_bertforpatents, I_bertforpatents = index_bertforpatents.search(query_vector_bertforpatents, k)\n",
    "D_climatebert, I_climatebert = index_climatebert.search(query_vector_climatebert, k)\n",
    "D_patentsberta, I_patentsberta = index_patentsberta.search(query_vector_patentsberta, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print row of df_keywords_claims that match the index\n",
    "df_keywords_claims.iloc[I_patentsberta[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity - kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity\n",
    "index_bertforpatents = faiss.index_factory(1024, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "index_climatebert = faiss.index_factory(768, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "index_patentsberta = faiss.index_factory(768, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "\n",
    "faiss.normalize_L2(np.array(df_keywords_claims['keyword_yake_bertforpatents_embedding'].tolist()))\n",
    "faiss.normalize_L2(np.array(df_keywords_claims['keyword_yake_climatebert_embedding'].tolist()))\n",
    "faiss.normalize_L2(np.array(df_keywords_claims['keyword_yake_patentsberta_embedding'].tolist()))\n",
    "\n",
    "index_bertforpatents.add(np.array(df_keywords_claims['keyword_yake_bertforpatents_embedding'].tolist()))\n",
    "index_climatebert.add(np.array(df_keywords_claims['keyword_yake_climatebert_embedding'].tolist()))\n",
    "index_patentsberta.add(np.array(df_keywords_claims['keyword_yake_patentsberta_embedding'].tolist()))\n",
    "\n",
    "query_vector_bertforpatents = np.array(df_search_test_titles['keyword_yake_bertforpatents_embedding'][0]).reshape(1, -1)\n",
    "query_vector_climatebert = np.array(df_search_test_titles['keyword_yake_climatebert_embedding'][0]).reshape(1, -1)\n",
    "query_vector_patentsberta = np.array(df_search_test_titles['keyword_yake_patentsberta_embedding'][0]).reshape(1, -1)\n",
    "\n",
    "faiss.normalize_L2(query_vector_bertforpatents)\n",
    "faiss.normalize_L2(query_vector_climatebert)\n",
    "faiss.normalize_L2(query_vector_patentsberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "D_bertforpatents, I_bertforpatents = index_bertforpatents.search(query_vector_bertforpatents, k)\n",
    "D_climatebert, I_climatebert = index_climatebert.search(query_vector_climatebert, k)\n",
    "D_patentsberta, I_patentsberta = index_patentsberta.search(query_vector_patentsberta, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print row of df_keywords_claims that match the index\n",
    "df_keywords_claims.iloc[I_bertforpatents[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity - Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of embeddings to a 2D array\n",
    "bertforpatents_embeddings = np.vstack(df_keywords_claims['keyword_yake_bertforpatents_embedding'].apply(np.array))\n",
    "climatebert_embeddings = np.vstack(df_keywords_claims['keyword_yake_climatebert_embedding'].apply(np.array))\n",
    "patentsberta_embeddings = np.vstack(df_keywords_claims['keyword_yake_patentsberta_embedding'].apply(np.array))\n",
    "\n",
    "# Normalize embeddings\n",
    "bertforpatents_embeddings_normalized = normalize(bertforpatents_embeddings)\n",
    "climatebert_embeddings_normalized = normalize(climatebert_embeddings)\n",
    "patentsberta_embeddings_normalized = normalize(patentsberta_embeddings)\n",
    "\n",
    "# Initialize NearestNeighbors with radius\n",
    "radius = 0.25\n",
    "nn_bertforpatents = NearestNeighbors(radius=radius, metric='cosine')\n",
    "nn_climatebert = NearestNeighbors(radius=radius, metric='cosine')\n",
    "nn_patentsberta = NearestNeighbors(radius=radius, metric='cosine')\n",
    "\n",
    "# Fit the models with normalized embeddings\n",
    "nn_bertforpatents.fit(bertforpatents_embeddings_normalized)\n",
    "nn_climatebert.fit(climatebert_embeddings_normalized)\n",
    "nn_patentsberta.fit(patentsberta_embeddings_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get keywords by indices\n",
    "def get_keywords_by_indices(indices, df_source):\n",
    "    return df_source.iloc[indices]['keyword_yake_lemma'].tolist() if indices.size else []\n",
    "\n",
    "# Extend df_keywords_titles with columns for keywords corresponding to the neighbor indices with empty lists\n",
    "df_keywords_titles['neighbors_bertforpatents'] = df_keywords_titles['keyword_yake_bertforpatents_embedding'].progress_apply(lambda x: [])\n",
    "df_keywords_titles['neighbors_climatebert'] = df_keywords_titles['keyword_yake_climatebert_embedding'].progress_apply(lambda x: [])\n",
    "df_keywords_titles['neighbors_patentsberta'] = df_keywords_titles['keyword_yake_patentsberta_embedding'].progress_apply(lambda x: [])\n",
    "\n",
    "df_keywords_titles['keywords_bertforpatents'] = df_keywords_titles['keyword_yake_bertforpatents_embedding'].progress_apply(lambda x: [])\n",
    "df_keywords_titles['keywords_climatebert'] = df_keywords_titles['keyword_yake_climatebert_embedding'].progress_apply(lambda x: [])\n",
    "df_keywords_titles['keywords_patentsberta'] = df_keywords_titles['keyword_yake_patentsberta_embedding'].progress_apply(lambda x: [])\n",
    "\n",
    "# Loop over each row in the DataFrame to use each set of embeddings as query vectors\n",
    "for index, row in tqdm(df_keywords_titles.iterrows()):\n",
    "    # Extract and normalize the query vectors\n",
    "    query_vector_bertforpatents = normalize(np.array([row['keyword_yake_bertforpatents_embedding']]).reshape(1, -1))\n",
    "    query_vector_climatebert = normalize(np.array([row['keyword_yake_climatebert_embedding']]).reshape(1, -1))\n",
    "    query_vector_patentsberta = normalize(np.array([row['keyword_yake_patentsberta_embedding']]).reshape(1, -1))\n",
    "    \n",
    "    # Find neighbors within the radius for each model\n",
    "    indices_bertforpatents = nn_bertforpatents.radius_neighbors(query_vector_bertforpatents, return_distance=False)\n",
    "    indices_climatebert = nn_climatebert.radius_neighbors(query_vector_climatebert, return_distance=False)\n",
    "    indices_patentsberta = nn_patentsberta.radius_neighbors(query_vector_patentsberta, return_distance=False)\n",
    "    \n",
    "    # Get the neighbors, or an empty array if none are found\n",
    "    neighbors_bertforpatents = indices_bertforpatents[0] if indices_bertforpatents[0].size else np.array([])\n",
    "    neighbors_climatebert = indices_climatebert[0] if indices_climatebert[0].size else np.array([])\n",
    "    neighbors_patentsberta = indices_patentsberta[0] if indices_patentsberta[0].size else np.array([])\n",
    "    \n",
    "    # Get the keywords from df_keywords_claims corresponding to the indices\n",
    "    keywords_bertforpatents = get_keywords_by_indices(neighbors_bertforpatents, df_keywords_claims)\n",
    "    keywords_climatebert = get_keywords_by_indices(neighbors_climatebert, df_keywords_claims)\n",
    "    keywords_patentsberta = get_keywords_by_indices(neighbors_patentsberta, df_keywords_claims)\n",
    "\n",
    "    # Assign the neighbors and keywords back to the DataFrame\n",
    "    df_keywords_titles.at[index, 'neighbors_bertforpatents'] = neighbors_bertforpatents.tolist()\n",
    "    df_keywords_titles.at[index, 'neighbors_climatebert'] = neighbors_climatebert.tolist()\n",
    "    df_keywords_titles.at[index, 'neighbors_patentsberta'] = neighbors_patentsberta.tolist()\n",
    "    df_keywords_titles.at[index, 'keywords_bertforpatents'] = keywords_bertforpatents\n",
    "    df_keywords_titles.at[index, 'keywords_climatebert'] = keywords_climatebert\n",
    "    df_keywords_titles.at[index, 'keywords_patentsberta'] = keywords_patentsberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_titles.to_json(f\"/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Similarity Search/df_keyword_titles_cosine_similarity_radius_{str(radius).replace('.','')}_noun_chunks.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
