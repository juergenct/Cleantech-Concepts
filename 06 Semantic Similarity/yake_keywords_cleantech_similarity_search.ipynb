{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_titles = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks_embeddings.json')\n",
    "\n",
    "# Convert columns 'keyword_patentsberta_embedding', 'keyword_climatebert_embedding', 'keyword_bertforpatents_embedding' to numpy arrays\n",
    "df_keywords_titles['keyword_yake_patentsberta_embedding'] = df_keywords_titles['keyword_yake_patentsberta_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_titles['keyword_yake_climatebert_embedding'] = df_keywords_titles['keyword_yake_climatebert_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_titles['keyword_yake_bertforpatents_embedding'] = df_keywords_titles['keyword_yake_bertforpatents_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_claims = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_noun_chunks.json')\n",
    "\n",
    "# Convert columns 'keyword_yake_patentsberta_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_bertforpatents_embedding' to numpy arrays\n",
    "df_keywords_claims['keyword_yake_patentsberta_embedding'] = df_keywords_claims['keyword_yake_patentsberta_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_claims['keyword_yake_climatebert_embedding'] = df_keywords_claims['keyword_yake_climatebert_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))\n",
    "df_keywords_claims['keyword_yake_bertforpatents_embedding'] = df_keywords_claims['keyword_yake_bertforpatents_embedding'].progress_apply(lambda x: np.array(x, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out all keyword_yake_lemma for cpc_class_symbol = Y02W\n",
    "print(df_keywords_titles[df_keywords_titles['cpc_class_symbol'].progress_apply(lambda x: 'Y02W10/33' in x)][['keyword_yake_lemma', 'cpc_class_symbol']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set search test to row with keyword = solar cells\n",
    "df_search_test_titles = df_keywords_titles[df_keywords_titles['keyword_yake_lemma'] == 'wind energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of df_search_test_titles\n",
    "df_search_test_titles.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_test_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean Distance - kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eucledian distance\n",
    "index_bertforpatents = faiss.IndexFlatL2(1024)   # build the index\n",
    "index_climatebert = faiss.IndexFlatL2(768)   # build the index\n",
    "index_patentsberta = faiss.IndexFlatL2(768)   # build the index\n",
    "\n",
    "# Add df_keywords_claims column 'keyword_yake_bertforpatents_embedding' to index\n",
    "index_bertforpatents.add(np.array(df_keywords_claims['keyword_yake_bertforpatents_embedding'].tolist()))\n",
    "index_climatebert.add(np.array(df_keywords_claims['keyword_yake_climatebert_embedding'].tolist()))\n",
    "index_patentsberta.add(np.array(df_keywords_claims['keyword_yake_patentsberta_embedding'].tolist()))\n",
    "\n",
    "query_vector_bertforpatents = np.array(df_search_test_titles['keyword_bertforpatents_embedding'][0]).reshape(1, -1)\n",
    "query_vector_climatebert = np.array(df_search_test_titles['keyword_climatebert_embedding'][0]).reshape(1, -1)\n",
    "query_vector_patentsberta = np.array(df_search_test_titles['keyword_patentsberta_embedding'][0]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 25\n",
    "D_bertforpatents, I_bertforpatents = index_bertforpatents.search(query_vector_bertforpatents, k)\n",
    "D_climatebert, I_climatebert = index_climatebert.search(query_vector_climatebert, k)\n",
    "D_patentsberta, I_patentsberta = index_patentsberta.search(query_vector_patentsberta, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print row of df_keywords_claims that match the index\n",
    "df_keywords_claims.iloc[I_patentsberta[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity - kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity\n",
    "index_bertforpatents = faiss.index_factory(1024, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "index_climatebert = faiss.index_factory(768, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "index_patentsberta = faiss.index_factory(768, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "\n",
    "faiss.normalize_L2(np.array(df_keywords_claims['keyword_yake_bertforpatents_embedding'].tolist()))\n",
    "faiss.normalize_L2(np.array(df_keywords_claims['keyword_yake_climatebert_embedding'].tolist()))\n",
    "faiss.normalize_L2(np.array(df_keywords_claims['keyword_yake_patentsberta_embedding'].tolist()))\n",
    "\n",
    "index_bertforpatents.add(np.array(df_keywords_claims['keyword_yake_bertforpatents_embedding'].tolist()))\n",
    "index_climatebert.add(np.array(df_keywords_claims['keyword_yake_climatebert_embedding'].tolist()))\n",
    "index_patentsberta.add(np.array(df_keywords_claims['keyword_yake_patentsberta_embedding'].tolist()))\n",
    "\n",
    "query_vector_bertforpatents = np.array(df_search_test_titles['keyword_yake_bertforpatents_embedding'][0]).reshape(1, -1)\n",
    "query_vector_climatebert = np.array(df_search_test_titles['keyword_yake_climatebert_embedding'][0]).reshape(1, -1)\n",
    "query_vector_patentsberta = np.array(df_search_test_titles['keyword_yake_patentsberta_embedding'][0]).reshape(1, -1)\n",
    "\n",
    "faiss.normalize_L2(query_vector_bertforpatents)\n",
    "faiss.normalize_L2(query_vector_climatebert)\n",
    "faiss.normalize_L2(query_vector_patentsberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "D_bertforpatents, I_bertforpatents = index_bertforpatents.search(query_vector_bertforpatents, k)\n",
    "D_climatebert, I_climatebert = index_climatebert.search(query_vector_climatebert, k)\n",
    "D_patentsberta, I_patentsberta = index_patentsberta.search(query_vector_patentsberta, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print row of df_keywords_claims that match the index\n",
    "df_keywords_claims.iloc[I_bertforpatents[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity - Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists of embeddings to a 2D array\n",
    "bertforpatents_embeddings = np.vstack(df_keywords_claims['keyword_yake_bertforpatents_embedding'].apply(np.array))\n",
    "climatebert_embeddings = np.vstack(df_keywords_claims['keyword_yake_climatebert_embedding'].apply(np.array))\n",
    "patentsberta_embeddings = np.vstack(df_keywords_claims['keyword_yake_patentsberta_embedding'].apply(np.array))\n",
    "\n",
    "# Normalize embeddings\n",
    "bertforpatents_embeddings_normalized = normalize(bertforpatents_embeddings)\n",
    "climatebert_embeddings_normalized = normalize(climatebert_embeddings)\n",
    "patentsberta_embeddings_normalized = normalize(patentsberta_embeddings)\n",
    "\n",
    "# Initialize NearestNeighbors with radius\n",
    "radius = 0.25\n",
    "nn_bertforpatents = NearestNeighbors(radius=radius, metric='cosine')\n",
    "nn_climatebert = NearestNeighbors(radius=radius, metric='cosine')\n",
    "nn_patentsberta = NearestNeighbors(radius=radius, metric='cosine')\n",
    "\n",
    "# Fit the models with normalized embeddings\n",
    "nn_bertforpatents.fit(bertforpatents_embeddings_normalized)\n",
    "nn_climatebert.fit(climatebert_embeddings_normalized)\n",
    "nn_patentsberta.fit(patentsberta_embeddings_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_by_indices(indices, df_source, k_neighbors=k_neighbors):\n",
    "    return df_source.iloc[indices[:k_neighbors]]['keyword_yake_lemma'].tolist() if len(indices) else []\n",
    "\n",
    "def process_embeddings(row, nn_model, df_keywords_claims, k_neighbors=100):\n",
    "    query_vector = normalize(np.array([row]).reshape(1, -1))\n",
    "    distances, indices = nn_model.radius_neighbors(query_vector)\n",
    "    neighbors = indices[0][:k_neighbors] if indices[0].size else np.array([])\n",
    "    keywords = get_keywords_by_indices(neighbors, df_keywords_claims, k_neighbors)\n",
    "    return neighbors.tolist(), keywords\n",
    "\n",
    "# Define the embeddings to process\n",
    "embeddings = ['keyword_yake_bertforpatents_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_patentsberta_embedding']\n",
    "nn_models = [nn_bertforpatents, nn_climatebert, nn_patentsberta]\n",
    "k_neighbors = 100  # Maximum number of neighbors to return\n",
    "\n",
    "# Process each embedding\n",
    "for embedding, nn_model in zip(embeddings, nn_models):\n",
    "    neighbors_col = f'neighbors_{embedding}'\n",
    "    keywords_col = f'keywords_{embedding}'\n",
    "\n",
    "    results = df_keywords_titles[embedding].progress_apply(lambda x: process_embeddings(x, nn_model, df_keywords_claims, k_neighbors))\n",
    "    df_keywords_titles[neighbors_col] = results.progress_apply(lambda x: x[0])\n",
    "    df_keywords_titles[keywords_col] = results.progress_apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_titles.to_json(f\"/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Similarity Search/df_keyword_titles_cosine_similarity_radius_{str(radius).replace('.','')}_neighbors_{str(k_neighbors)}_noun_chunks.json\", orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
