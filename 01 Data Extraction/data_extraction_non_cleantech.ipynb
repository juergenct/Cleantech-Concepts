{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPTO - Patent ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cpc_uspto = pd.read_csv('/mnt/hdd01/patentsview/Raw files/Raw csv files/g_cpc_current.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all the CPC codes for each patent\n",
    "g_cpc_uspto_agg = g_cpc_uspto.groupby('patent_id')['cpc_class'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 600.000 patents from the aggregated dataset, where 'cpc_class' does not contain \"Y02\"\n",
    "g_cpc_uspto_agg_non_cleantech = g_cpc_uspto_agg[~g_cpc_uspto_agg['cpc_class'].progress_apply(lambda x: any('Y02' in s for s in x))]\n",
    "g_cpc_uspto_agg_non_cleantech_sample = g_cpc_uspto_agg_non_cleantech.sample(n=600000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_cpc_uspto_agg_non_cleantech_sample.to_csv('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/g_uspto_non_cleantech_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliance on Science - oaid's (USPTO + EPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oaid_uspto = pd.read_csv('/mnt/hdd01/patentsview/Reliance on Science - Cleantech Patents/df_oaid_Cleantech_Y02.csv', usecols=['oaid', 'patent_id'], dtype={'oaid': str, 'patent_id': str})\n",
    "df_oaid_epo = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/Reliance on Science/cleantech_epo_rel_on_science_abstract.json', dtype={'oaid': str, 'publn_nr': str})\n",
    "# Drop all columns in df_oaid_epo except 'oaid' and 'publn_nr'\n",
    "df_oaid_epo = df_oaid_epo[['oaid', 'publn_nr']]\n",
    "# Delete everything after the '.' in oaid in df_oaid_uspto\n",
    "df_oaid_uspto['oaid'] = df_oaid_uspto['oaid'].str.split('.').str[0]\n",
    "# Merge df_oaid_uspto and df_oaid_epo on 'oaid'\n",
    "df_oaid_uspto_epo = pd.merge(df_oaid_uspto, df_oaid_epo, on='oaid', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcs = pd.read_csv('/mnt/hdd01/Reliance on Science/Raw Files/_pcs_oa.csv', dtype={'oaid': str, 'patent_id': str})\n",
    "# Extract everything before first hypen in column 'patent' into new column 'origin'\n",
    "df_pcs['origin'] = df_pcs['patent'].str.split('-').str[0]\n",
    "# Limit df_pcs to only patents with origin 'us' or 'ep'\n",
    "df_pcs = df_pcs[(df_pcs['origin'] == 'us') | (df_pcs['origin'] == 'ep')]\n",
    "# Aggregate df_pcs on oaid and list all patent\n",
    "df_pcs_agg = df_pcs.groupby('oaid')['patent'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 800.000 patents from df_pcs where 'oaid' is not in df_oaid_uspto_epo\n",
    "df_pcs_non_cleantech = df_pcs_agg[~df_pcs_agg['oaid'].isin(df_oaid_uspto_epo['oaid'])]\n",
    "df_pcs_non_cleantech = df_pcs_non_cleantech.sample(n=800000, random_state=42)\n",
    "# Add column 'full_oaid' with https://openalex.org/W + oaid\n",
    "df_pcs_non_cleantech['full_oaid'] = 'https://openalex.org/W' + df_pcs_non_cleantech['oaid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7fd32c33a350>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, URL\n",
    "\n",
    "url_object = URL.create(\n",
    "    drivername='postgresql+psycopg2',\n",
    "    username='tie',\n",
    "    password='TIE%2023!tuhh',\n",
    "    # host='134.28.58.100',\n",
    "    # host='tie-workstation.tail6716.ts.net',\n",
    "    host='localhost',\n",
    "    port=45432,\n",
    "    database='openalex_db',\n",
    ")\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine(url_object)\n",
    "# Check if connection is successful\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert temporary table into database\n",
    "df_pcs_non_cleantech.to_sql('temp_table', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pcs_non_cleantech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to sample df_pcs_non_cleantech column 'full_oaid' from works.id in openalex.works\n",
    "sql_query = f'''\n",
    "    SELECT *\n",
    "    FROM openalex.works \n",
    "    JOIN temp_table ON openalex.works.id = temp_table.full_oaid\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_oaids_df = pd.read_sql(sql_query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "777693it [01:08, 11343.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over abstract_inverted_index columnc\n",
    "for index, row in tqdm(sampled_oaids_df.iterrows()):\n",
    "    word_index = []\n",
    "    try:\n",
    "        for key, value in row['abstract_inverted_index'].items():\n",
    "            if key == 'InvertedIndex':\n",
    "                for innerkey, innervalue in value.items():\n",
    "                    for innerindex in innervalue:\n",
    "                        word_index.append([innerkey, innerindex])\n",
    "        # Sort list by index\n",
    "        word_index.sort(key=lambda x: x[1])\n",
    "        # Join first element of each list in word_index\n",
    "        abstract = ' '.join([i[0] for i in word_index])\n",
    "        # Add column abstract to result dataframe\n",
    "        # result.loc[index, 'abstract'] = abstract\n",
    "        sampled_oaids_df.at[index, 'abstract'] = abstract\n",
    "        # print(result.loc[index, 'abstract'])\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns where abstract is None\n",
    "sampled_oaids_df = sampled_oaids_df[sampled_oaids_df['abstract'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_oaids_df.to_json('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/df_oaids_non_cleantech.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epo = pd.read_csv('/mnt/hdd01/PATSTAT Working Directory/PATSTAT/Cleantech Patent Raw Data/cleantech_ep_granted.csv', dtype={'publn_nr': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:  database \"Patstat\" has a collation version mismatch\n",
      "DETAIL:  The database was created using collation version 2.31, but the operating system provides version 2.36.\n",
      "HINT:  Rebuild all objects in this database that use the default collation and run ALTER DATABASE \"Patstat\" REFRESH COLLATION VERSION, or build PostgreSQL with the right library version.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7ff8169921d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, URL\n",
    "\n",
    "url_object = URL.create(\n",
    "    drivername='postgresql+psycopg2',\n",
    "    username='tie',\n",
    "    password='TIE%2023!tuhh',\n",
    "    # host='134.28.58.100',\n",
    "    # host='tie-workstation.tail6716.ts.net',\n",
    "    host='localhost',\n",
    "    port=25432,\n",
    "    database='Patstat',\n",
    ")\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine(url_object)\n",
    "# Check if connection is successful\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1343716',\n",
       " '1276322',\n",
       " '1556493',\n",
       " '1171962',\n",
       " '1242729',\n",
       " '0128347',\n",
       " '0161004',\n",
       " '0464372',\n",
       " '0656321',\n",
       " '1227840')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publn_nr_cleantech = tuple(df_epo['publn_nr'].tolist())\n",
    "publn_nr_cleantech[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_epo = \"\"\"\n",
    "    SELECT pub.*\n",
    "    FROM tls211_pat_publn AS pub\n",
    "    JOIN tls201_appln AS appln ON pub.appln_id = appln.appln_id\n",
    "    JOIN tls224_appln_cpc AS cpc ON pub.appln_id = cpc.appln_id\n",
    "    WHERE pub.publn_nr NOT IN %(publn_nr_list)s\n",
    "    AND appln.appln_auth = 'EP'\n",
    "    AND appln.granted = 'Y'\n",
    "    AND cpc.cpc_class_symbol NOT LIKE '%%Y02%%'\n",
    "    AND NOT EXISTS (\n",
    "        SELECT 1\n",
    "        FROM tls224_appln_cpc as cpc2\n",
    "        WHERE cpc2.appln_id = pub.appln_id \n",
    "        AND cpc2.cpc_class_symbol LIKE '%%Y02%%'\n",
    "    )\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 200000;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'publn_nr_list': publn_nr_cleantech}\n",
    "df_epo_non_cleantech = pd.read_sql(sql_query_epo, engine, params=params)\n",
    "# Maybe I should also extract appln info and cpc info for each patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except publn_nr, appln_id and publn_date\n",
    "df_epo_non_cleantech = df_epo_non_cleantech[['publn_nr', 'appln_id', 'publn_date']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
