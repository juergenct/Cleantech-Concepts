{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_yake_cleantech_keywords = pd.read_json('data/yake_cleantech_keywords.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bertforpatents = SentenceTransformer('anferico/bert-for-patents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU available: {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_keywords['bertforpatents_embedding'] = model_bertforpatents.encode(df_yake_cleantech_keywords['keyword'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction (Open TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openTSNE import TSNE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertforpatents_x_train, bertforpatents_x_test = train_test_split(df_yake_cleantech_keywords['bertforpatents_embedding'].tolist(), test_size=0.2, random_state=42)\n",
    "# Convert to numpy array\n",
    "bertforpatents_x_train = np.array(bertforpatents_x_train)\n",
    "bertforpatents_x_test = np.array(bertforpatents_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    perplexity=30,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    n_iter=1000,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-SNE\n",
    "bertforpatents_embedding_train = tsne.fit(bertforpatents_x_train)\n",
    "bertforpatents_embedding_test = bertforpatents_embedding_train.transform(bertforpatents_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_keywords['bertforpatents_embedding_tsne'] = np.concatenate((bertforpatents_embedding_train, bertforpatents_embedding_test), axis=0).tolist()\n",
    "df_yake_cleantech_keywords['bertforpatents_embedding_tsne_x'] = df_yake_cleantech_keywords['bertforpatents_embedding_tsne'].apply(lambda x: x[0])\n",
    "df_yake_cleantech_keywords['bertforpatents_embedding_tsne_y'] = df_yake_cleantech_keywords['bertforpatents_embedding_tsne'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering (HDBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform HDBSCAN clustering on the UMAP coordinates\n",
    "clusterer_bertforpatents = hdbscan.HDBSCAN(min_cluster_size=100, min_samples=1).fit(df_yake_cleantech_keywords['bertforpatents_embedding_tsne'].tolist())\n",
    "df_yake_cleantech_keywords['bertforpatents_cluster'] = clusterer_bertforpatents.labels_.tolist()\n",
    "\n",
    "# Erase all rows with cluster -1\n",
    "df_yake_cleantech_keywords = df_yake_cleantech_keywords[df_yake_cleantech_keywords['bertforpatents_cluster'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Cluster (HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the keywords per cluster\n",
    "df_yake_cleantech_keywords_cluster = df_yake_cleantech_keywords.groupby(['bertforpatents_cluster'])['keyword'].apply(list).reset_index(name='keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a text-generation pipeline with Flan-T5-large\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = pipeline('text2text-generation', model='google/flan-t5-large', device=device)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cluster_name(keywords):\n",
    "    # Ensure the keywords are in a list format\n",
    "    keywords = keywords.split(', ') if isinstance(keywords, str) else keywords\n",
    "    # Select only the first xxx keywords from the list\n",
    "    selected_keywords = keywords[:2000]\n",
    "    # Join the selected keywords into a string format\n",
    "    keywords_str = ', '.join(selected_keywords)\n",
    "    # Create a prompt from the selected keywords\n",
    "    # prompt = f\"Based on the following keywords, come up with a specific, precise and short topic name: {keywords_str}\"\n",
    "    prompt = f\"Generate a concise and descriptive common theme or category for a cluster containing the following keywords: {keywords_str}.\" # The name should be in title case and should not exceed three words.\"\n",
    "    # Doesn't work at all -> only focuses on electric vehicle innovation# prompt = f\"Given the keywords: {keywords_str}, provide a succinct cluster name similar to how 'Electric Vehicle Innovation' represents keywords like 'battery technology, electric motor, charging infrastructure'.\"\n",
    "    # prompt = f\"Identify a common theme or category for the following keywords: {keywords_str}. Provide a concise, descriptive name for this theme or category.\"\n",
    "    # prompt = f\"The keywords {keywords_str} all belong to the category: _____\"\n",
    "    # Generate a response using the GPT-3 model\n",
    "    response = generator(prompt, max_length=10, do_sample=True, temperature=0.8)[0]['generated_text']\n",
    "    # Extract the cluster name from the response\n",
    "    cluster_name = response\n",
    "    return cluster_name\n",
    "\n",
    "# Apply the function to the 'keywords' column to generate cluster names\n",
    "df_yake_cleantech_keywords_cluster['cluster_name'] = df_yake_cleantech_keywords_cluster['keywords'].progress_apply(generate_cluster_name)\n",
    "df_yake_cleantech_keywords['cluster_name'] = df_yake_cleantech_keywords['bertforpatents_cluster'].map(df_yake_cleantech_keywords_cluster.set_index('bertforpatents_cluster')['cluster_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization (Plotly Express)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_bertforpatents = px.scatter(\n",
    "    df_yake_cleantech_keywords,\n",
    "    x='bertforpatents_embedding_tsne_x',\n",
    "    y='bertforpatents_embedding_tsne_y',\n",
    "    color='bertforpatents_cluster',\n",
    "    hover_data=['keyword', 'cluster_name'],\n",
    "    title='HDBSCAN clustering of YAKE keywords using BERT for patents embeddings',\n",
    "    height=800,\n",
    "    width=800\n",
    ")\n",
    "\n",
    "fig_bertforpatents.show()\n",
    "\n",
    "fig_bertforpatents.write_html('data/yake_keywords_noun_chunks_dim_reduction_cluster.html')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
