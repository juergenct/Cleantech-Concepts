{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import multiprocessing as mp\n",
    "from wordtrie import WordTrie\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_lemmatize(text):\n",
    "    \"\"\"\n",
    "    Normalize, clean, and lemmatize the input text.\n",
    "\n",
    "    :param text: A string containing the text to be processed.\n",
    "    :return: A string representing the processed text.\n",
    "    \"\"\"\n",
    "    # Normalize the text with unicodedata\n",
    "    text = unicodedata.normalize(\"NFKD\", text).encode('ASCII', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Remove URLs, brackets, and non-alphabetic characters; convert to lowercase\n",
    "    text = re.sub(r\"\\[.*?\\]|\\(.*?\\)|\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"https?:\\/\\/\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z- ]\", \" \", text).lower().strip()\n",
    "\n",
    "    # Lemmatize each word\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Cleantech Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Cleantech Data\n",
    "# Co-Occurrence Directory\n",
    "# co_occurrence_dir = '/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Co-Occurrence Analysis/'\n",
    "# co_occurrence_files = glob.glob(co_occurrence_dir + '*.csv')\n",
    "co_occurrence_files = '/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Co-Occurrence Analysis/co_occurrence_matrix_yake_keywords_cleantech_uspto_epo_rel_ids_semantic_similarity_02.csv'\n",
    "\n",
    "# Similarity Directory\n",
    "# similarity_dir = '/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Similarity Search/'\n",
    "# similarity_files = glob.glob(similarity_dir + '*.json')\n",
    "similarity_files = '/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Similarity Search/df_keyword_titles_cosine_similarity_radius_025_neighbors_100_noun_chunks.json'\n",
    "\n",
    "# Co-Occurrence Threshold\n",
    "# co_occurrence_threshold = [0.01, 0.025, 0.05, 0.1, 0.15]\n",
    "co_occurrence_threshold = [0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_411379/2481430203.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mask = df_cleantech_cooccurrence.applymap(lambda x: x >= co_occurrence_threshold)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df_cleantech_cooccurrence = pd.read_csv(co_occurrence_files, index_col=0)\n",
    "df_cleantech_cooccurrence.dropna(how='all', inplace=True)\n",
    "\n",
    "df_cleantech_similarity = pd.read_json(similarity_files)\n",
    "\n",
    "# Co-Occurrence Threshold\n",
    "co_occurrence_threshold = 0.01  # Assuming you are using a single threshold value\n",
    "\n",
    "# Create a mask for the co-occurrence threshold\n",
    "mask = df_cleantech_cooccurrence.applymap(lambda x: x >= co_occurrence_threshold)\n",
    "\n",
    "# Apply mask to DataFrame\n",
    "filtered_co_occurrence_df = df_cleantech_cooccurrence[mask]\n",
    "\n",
    "# Extract keywords\n",
    "co_occurrence_list = filtered_co_occurrence_df.columns[filtered_co_occurrence_df.any()].tolist()\n",
    "\n",
    "# Processing similarity data\n",
    "similarity_series = pd.concat([df_cleantech_similarity['keyword_yake_lemma'], df_cleantech_similarity['keywords_keyword_yake_bertforpatents_embedding'].explode()], ignore_index=True)\n",
    "similarity_list = similarity_series.drop_duplicates().tolist()\n",
    "\n",
    "# Combine and deduplicate lists\n",
    "cleantech_list = list(set(co_occurrence_list + similarity_list))\n",
    "cleantech_list = [str(keyword) for keyword in cleantech_list]\n",
    "\n",
    "# # Create DataFrame\n",
    "df_cleantech = pd.DataFrame(cleantech_list, columns=['keyword_yake_lemma'])\n",
    "# df_cleantech['cleantech'] = 1\n",
    "\n",
    "del df_cleantech_cooccurrence\n",
    "del df_cleantech_similarity\n",
    "del co_occurrence_list\n",
    "del similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 14866 keywords to trie\n"
     ]
    }
   ],
   "source": [
    "# Build WordTrie\n",
    "def make_wordtrie(keyword_list):\n",
    "    trie = WordTrie()\n",
    "    if keyword_list is None:\n",
    "        return None\n",
    "    i = 0\n",
    "    for keyword in keyword_list:\n",
    "        if isinstance(keyword, str):\n",
    "            trie.add(keyword, i)\n",
    "            i += 1\n",
    "    print(f\"Added {i} keywords to trie\")\n",
    "    return trie\n",
    "\n",
    "# Build WordTrie\n",
    "cleantech_trie = make_wordtrie(df_cleantech['keyword_yake_lemma'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Trie Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPTO - Cleantech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "g_uspto_cleantech = pd.read_json('/mnt/hdd01/patentsview/Patentsview - Cleantech Patents/g_patent_claims_fulltext_cleantech.json')\n",
    "g_uspto_cleantech['patent_id'] = 'us-' + g_uspto_cleantech['patent_id'].astype(str)\n",
    "\n",
    "# Create a pool of workers\n",
    "pool = mp.Pool(min(mp.cpu_count(),6))\n",
    "\n",
    "# Apply the function to the 'claim_fulltext' column using the pool of workers\n",
    "results = []\n",
    "for result in tqdm(pool.imap(clean_and_lemmatize, g_uspto_cleantech['claim_fulltext']), total=g_uspto_cleantech.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "g_uspto_cleantech['claim_fulltext'] = results\n",
    "\n",
    "# Close the pool\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the search and explode the trie\n",
    "g_uspto_cleantech[\"trie\"] = g_uspto_cleantech[\"claim_fulltext\"].progress_apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "g_uspto_cleantech[\"trie\"] = g_uspto_cleantech[\"trie\"].progress_apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_uspto_cleantech = g_uspto_cleantech[['patent_id', 'trie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_uspto_cleantech.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/TFIDF Matrices/g_uspto_cleantech_trie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPTO - Non Cleantech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599997/599997 [06:03<00:00, 1652.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "g_uspto_non_cleantech = pd.read_json('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/g_uspto_non_cleantech_claims_fulltext.json')\n",
    "g_uspto_non_cleantech['patent_id'] = 'us-' + g_uspto_non_cleantech['patent_id'].astype(str)\n",
    "\n",
    "# Create a pool of workers\n",
    "pool = mp.Pool(min(mp.cpu_count(),6))\n",
    "\n",
    "# Apply the function to the 'claim_fulltext' column using the pool of workers\n",
    "results = []\n",
    "for result in tqdm(pool.imap(clean_and_lemmatize, g_uspto_non_cleantech['claim_fulltext']), total=g_uspto_non_cleantech.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "g_uspto_non_cleantech['claim_fulltext'] = results\n",
    "\n",
    "# Close the pool\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 599997/599997 [03:39<00:00, 2739.50it/s]\n",
      "100%|██████████| 599997/599997 [00:12<00:00, 49927.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the search and explode the trie\n",
    "g_uspto_non_cleantech[\"trie\"] = g_uspto_non_cleantech[\"claim_fulltext\"].progress_apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "g_uspto_non_cleantech[\"trie\"] = g_uspto_non_cleantech[\"trie\"].progress_apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_uspto_non_cleantech = g_uspto_non_cleantech[['patent_id', 'trie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_uspto_non_cleantech.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/TFIDF Matrices/g_uspto_non_cleantech_trie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPO - Cleantech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179597/179597 [00:31<00:00, 5752.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "g_epo_cleantech = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/PATSTAT/cleantech_epo_text_data_pivot_cleaned.json')\n",
    "g_epo_cleantech['patent_id'] = 'ep-' + g_epo_cleantech['publn_nr'].astype(str)\n",
    "\n",
    "# Create a pool of workers\n",
    "pool = mp.Pool(min(mp.cpu_count(),6))\n",
    "\n",
    "# Delete all rows where 'cleaned_claims' is not str\n",
    "g_epo_cleantech = g_epo_cleantech[g_epo_cleantech['cleaned_claims'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Apply the function to the 'cleaned_claims' column using the pool of workers\n",
    "results = []\n",
    "for result in tqdm(pool.imap(clean_and_lemmatize, g_epo_cleantech['cleaned_claims']), total=g_epo_cleantech.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "g_epo_cleantech['cleaned_claims'] = results\n",
    "\n",
    "# Close the pool\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179597/179597 [00:25<00:00, 7135.26it/s]\n",
      "100%|██████████| 179597/179597 [00:02<00:00, 59902.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the search and explode the trie\n",
    "g_epo_cleantech[\"trie\"] = g_epo_cleantech[\"cleaned_claims\"].progress_apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "g_epo_cleantech[\"trie\"] = g_epo_cleantech[\"trie\"].progress_apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except 'publn_nr' and 'trie'\n",
    "g_epo_cleantech = g_epo_cleantech[['publn_nr', 'trie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_epo_cleantech.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/TFIDF Matrices/g_epo_cleantech_trie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPO - Non Cleantech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181920/181920 [00:33<00:00, 5458.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "g_epo_non_cleantech = pd.read_json('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/df_epo_non_cleantech_text_data_pivot_claims_cleaned.json')\n",
    "g_epo_non_cleantech['publn_nr'] = 'ep-' + g_epo_non_cleantech['publn_nr'].astype(str)\n",
    "\n",
    "# Create a pool of workers\n",
    "pool = mp.Pool(min(mp.cpu_count(),6))\n",
    "\n",
    "# Apply the function to the 'cleaned_claims' column using the pool of workers\n",
    "results = []\n",
    "for result in tqdm(pool.imap(clean_and_lemmatize, g_epo_non_cleantech['cleaned_claims']), total=g_epo_non_cleantech.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "g_epo_non_cleantech['cleaned_claims'] = results\n",
    "\n",
    "# Close the pool\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181920/181920 [01:13<00:00, 2478.78it/s]\n",
      "100%|██████████| 181920/181920 [00:03<00:00, 53520.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the search and explode the trie\n",
    "g_epo_non_cleantech[\"trie\"] = g_epo_non_cleantech[\"cleaned_claims\"].progress_apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "g_epo_non_cleantech[\"trie\"] = g_epo_non_cleantech[\"trie\"].progress_apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_epo_non_cleantech = g_epo_non_cleantech[['publn_nr', 'trie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_epo_non_cleantech.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/TFIDF Matrices/g_epo_non_cleantech_trie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REL - Cleantech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "g_rel_cleantech = pd.read_json('/mnt/hdd01/patentsview/Reliance on Science - Cleantech Patents/df_oaid_cleantech_yake_noun_chunks.json')\n",
    "g_rel_cleantech['oaid'] = 'rel-' + g_rel_cleantech['oaid'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623364/623364 [01:03<00:00, 9756.52it/s] \n"
     ]
    }
   ],
   "source": [
    "# Create a pool of workers\n",
    "pool = mp.Pool(min(mp.cpu_count(),6))\n",
    "\n",
    "# Apply the function to the 'abstract' column using the pool of workers\n",
    "results = []\n",
    "for result in tqdm(pool.imap(clean_and_lemmatize, g_rel_cleantech['abstract']), total=g_rel_cleantech.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "g_rel_cleantech['abstract'] = results\n",
    "\n",
    "# Close the pool\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623364/623364 [01:32<00:00, 6747.32it/s] \n",
      "100%|██████████| 623364/623364 [00:03<00:00, 167414.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the search and explode the trie\n",
    "g_rel_cleantech[\"trie\"] = g_rel_cleantech[\"abstract\"].progress_apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "g_rel_cleantech[\"trie\"] = g_rel_cleantech[\"trie\"].progress_apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_rel_cleantech = g_rel_cleantech[['oaid', 'trie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_rel_cleantech.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/TFIDF Matrices/g_rel_cleantech_trie.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REL - Non Cleantech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611441/611441 [00:48<00:00, 12620.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "g_rel_non_cleantech = pd.read_json('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/df_oaids_non_cleantech.json')\n",
    "g_rel_non_cleantech['oaid'] = 'rel-' + g_rel_non_cleantech['oaid'].astype(str)\n",
    "\n",
    "# Create a pool of workers\n",
    "pool = mp.Pool(min(mp.cpu_count(),6))\n",
    "\n",
    "# Apply the function to the 'abstract' column using the pool of workers\n",
    "results = []\n",
    "for result in tqdm(pool.imap(clean_and_lemmatize, g_rel_non_cleantech['abstract']), total=g_rel_non_cleantech.shape[0]):\n",
    "    results.append(result)\n",
    "\n",
    "g_rel_non_cleantech['abstract'] = results\n",
    "\n",
    "# Close the pool\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611441/611441 [01:04<00:00, 9467.14it/s] \n",
      "100%|██████████| 611441/611441 [00:02<00:00, 218185.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform the search and explode the trie\n",
    "g_rel_non_cleantech[\"trie\"] = g_rel_non_cleantech[\"abstract\"].progress_apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "g_rel_non_cleantech[\"trie\"] = g_rel_non_cleantech[\"trie\"].progress_apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_rel_non_cleantech = g_rel_non_cleantech[['oaid', 'trie']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "g_rel_non_cleantech.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/TFIDF Matrices/g_rel_non_cleantech_trie.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
