{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_patents = pd.read_csv('/Users/juergenthiesen/Documents/Patentsview/Cleantech CSV Files/g_patent_Y02.csv')\n",
    "df_cpc = pd.read_csv('/Users/juergenthiesen/Documents/Patentsview/Cleantech CSV Files/g_cpc_current_Y02.csv')\n",
    "\n",
    "# Drop all classes uneqaul to Y02 from df_cpc\n",
    "df_cpc = df_cpc[df_cpc['cpc_class'].str.contains('Y02')]\n",
    "\n",
    "# Merge data on patent_id, keep duplicates\n",
    "df = pd.merge(df_patents, df_cpc, on='patent_id', how='left')\n",
    "\n",
    "# Drop all data in df with title or abstract NaN\n",
    "df = df.dropna(subset=['patent_title', 'patent_abstract'])\n",
    "\n",
    "# Merge title and abstract with [SEP] token\n",
    "df['patent_title_abstract'] = df['patent_title'] + ' [SEP] ' + df['patent_abstract']\n",
    "\n",
    "# Randomly sample 1000 patents per cpc_subclass\n",
    "df = df.groupby('cpc_subclass').apply(lambda x: x.sample(1000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/juergenthiesen/.cache/torch/sentence_transformers/climatebert_distilroberta-base-climate-f. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /Users/juergenthiesen/.cache/torch/sentence_transformers/climatebert_distilroberta-base-climate-f were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /Users/juergenthiesen/.cache/torch/sentence_transformers/climatebert_distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Walk through BERTopic initialization\n",
    "\n",
    "# Generate embeddings\n",
    "embedding_model = SentenceTransformer('climatebert/distilroberta-base-climate-f')\n",
    "\n",
    "# Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='euclidean')\n",
    "\n",
    "# Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Fine-tune topic representations\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    representation_model=representation_model,\n",
    "    min_topic_size=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list from column patent_title_abstract\n",
    "patent_title_abstract = df['patent_title_abstract'].tolist()\n",
    "# Fit topic model\n",
    "topic, probs = topic_model.fit_transform(patent_title_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Visualize topics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m topic_model\u001b[39m.\u001b[39;49mvisualize_topics()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/bertopic/_bertopic.py:2193\u001b[0m, in \u001b[0;36mBERTopic.visualize_topics\u001b[0;34m(self, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Visualize topics, their sizes, and their corresponding words\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m \n\u001b[1;32m   2165\u001b[0m \u001b[39mThis visualization is highly inspired by LDAvis, a great visualization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2190\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m   2191\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 2193\u001b[0m \u001b[39mreturn\u001b[39;00m plotting\u001b[39m.\u001b[39;49mvisualize_topics(\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2194\u001b[0m                                  topics\u001b[39m=\u001b[39;49mtopics,\n\u001b[1;32m   2195\u001b[0m                                  top_n_topics\u001b[39m=\u001b[39;49mtop_n_topics,\n\u001b[1;32m   2196\u001b[0m                                  custom_labels\u001b[39m=\u001b[39;49mcustom_labels,\n\u001b[1;32m   2197\u001b[0m                                  title\u001b[39m=\u001b[39;49mtitle,\n\u001b[1;32m   2198\u001b[0m                                  width\u001b[39m=\u001b[39;49mwidth,\n\u001b[1;32m   2199\u001b[0m                                  height\u001b[39m=\u001b[39;49mheight)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/bertopic/plotting/_topics.py:79\u001b[0m, in \u001b[0;36mvisualize_topics\u001b[0;34m(topic_model, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m topic_model\u001b[39m.\u001b[39mtopic_embeddings_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     embeddings \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39mtopic_embeddings_[indices]\n\u001b[0;32m---> 79\u001b[0m     embeddings \u001b[39m=\u001b[39m UMAP(n_neighbors\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcosine\u001b[39;49m\u001b[39m'\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(embeddings)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     embeddings \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39mc_tf_idf_\u001b[39m.\u001b[39mtoarray()[indices]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/umap/umap_.py:2772\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2742\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2743\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[1;32m   2744\u001b[0m \u001b[39m    output.\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2770\u001b[0m \u001b[39m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[1;32m   2771\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2772\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m   2773\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2774\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dens:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/umap/umap_.py:2684\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2681\u001b[0m     \u001b[39mprint\u001b[39m(ts(), \u001b[39m\"\u001b[39m\u001b[39mConstruct embedding\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2684\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_, aux_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_embed_data(\n\u001b[1;32m   2685\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_data[index],\n\u001b[1;32m   2686\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_epochs,\n\u001b[1;32m   2687\u001b[0m         init,\n\u001b[1;32m   2688\u001b[0m         random_state,  \u001b[39m# JH why raw data?\u001b[39;49;00m\n\u001b[1;32m   2689\u001b[0m     )\n\u001b[1;32m   2690\u001b[0m     \u001b[39m# Assign any points that are fully disconnected from our manifold(s) to have embedding\u001b[39;00m\n\u001b[1;32m   2691\u001b[0m     \u001b[39m# coordinates of np.nan.  These will be filtered by our plotting functions automatically.\u001b[39;00m\n\u001b[1;32m   2692\u001b[0m     \u001b[39m# They also prevent users from being deceived a distance query to one of these points.\u001b[39;00m\n\u001b[1;32m   2693\u001b[0m     \u001b[39m# Might be worth moving this into simplicial_set_embedding or _fit_embed_data\u001b[39;00m\n\u001b[1;32m   2694\u001b[0m     disconnected_vertices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mflatten() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/umap/umap_.py:2717\u001b[0m, in \u001b[0;36mUMAP._fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[1;32m   2713\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_embed_data\u001b[39m(\u001b[39mself\u001b[39m, X, n_epochs, init, random_state):\n\u001b[1;32m   2714\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A method wrapper for simplicial_set_embedding that can be\u001b[39;00m\n\u001b[1;32m   2715\u001b[0m \u001b[39m    replaced by subclasses.\u001b[39;00m\n\u001b[1;32m   2716\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2717\u001b[0m     \u001b[39mreturn\u001b[39;00m simplicial_set_embedding(\n\u001b[1;32m   2718\u001b[0m         X,\n\u001b[1;32m   2719\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_,\n\u001b[1;32m   2720\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[1;32m   2721\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initial_alpha,\n\u001b[1;32m   2722\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a,\n\u001b[1;32m   2723\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b,\n\u001b[1;32m   2724\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepulsion_strength,\n\u001b[1;32m   2725\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_sample_rate,\n\u001b[1;32m   2726\u001b[0m         n_epochs,\n\u001b[1;32m   2727\u001b[0m         init,\n\u001b[1;32m   2728\u001b[0m         random_state,\n\u001b[1;32m   2729\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_distance_func,\n\u001b[1;32m   2730\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metric_kwds,\n\u001b[1;32m   2731\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdensmap,\n\u001b[1;32m   2732\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_densmap_kwds,\n\u001b[1;32m   2733\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_dens,\n\u001b[1;32m   2734\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_distance_func,\n\u001b[1;32m   2735\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_metric_kwds,\n\u001b[1;32m   2736\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_metric \u001b[39min\u001b[39;49;00m (\u001b[39m\"\u001b[39;49m\u001b[39meuclidean\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39ml2\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   2737\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2738\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   2739\u001b[0m         tqdm_kwds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtqdm_kwds,\n\u001b[1;32m   2740\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/umap/umap_.py:1066\u001b[0m, in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     n_epochs \u001b[39m=\u001b[39m default_epochs\n\u001b[1;32m   1065\u001b[0m \u001b[39mif\u001b[39;00m n_epochs \u001b[39m>\u001b[39m \u001b[39m10\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m     graph\u001b[39m.\u001b[39mdata[graph\u001b[39m.\u001b[39mdata \u001b[39m<\u001b[39m (graph\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mmax() \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(n_epochs))] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m   1067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1068\u001b[0m     graph\u001b[39m.\u001b[39mdata[graph\u001b[39m.\u001b[39mdata \u001b[39m<\u001b[39m (graph\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mmax() \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(default_epochs))] \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/lib/python3.10/site-packages/numpy/core/_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[39mNone\u001b[39;49;00m, out, keepdims, initial, where)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# Visualize topics\n",
    "topic_model.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
