{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_yake_claims_ep = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/PATSTAT/cleantech_epo_text_data_pivot_cleaned_yake_noun_chunks.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182369/182369 [00:00<00:00, 607237.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def parse_strings(s):\n",
    "    # Check if the string starts with [' and ends with ']\n",
    "    if s.startswith(\"['\") and s.endswith(\"']\"):\n",
    "        # Use a regular expression to find all sequences of characters enclosed in single or double quotes\n",
    "        return re.findall(r\"['\\\"]([^'\\\"]*)['\\\"]\", s)\n",
    "    else:\n",
    "        # Split the string by commas\n",
    "        return s.split(', ')\n",
    "    \n",
    "# Apply parse_strings function to 'cpc_class_symbol' column\n",
    "df_yake_claims_ep['cpc_class_symbol'] = df_yake_claims_ep['cpc_class_symbol'].progress_apply(parse_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182369it [00:10, 17678.73it/s]\n"
     ]
    }
   ],
   "source": [
    "keywords_list_ep = []\n",
    "yake_conf_score_list = []\n",
    "publn_nr_list = []\n",
    "cpc_symbol_list = []\n",
    "# min_yake_conf = 0.05 - Currently not used\n",
    "\n",
    "# Iterate over rows in dataframe\n",
    "for index, row in tqdm(df_yake_claims_ep.iterrows()):\n",
    "    # Check if 'keywords_yake_claims' column is not a list\n",
    "    if not isinstance(row['keywords_yake_claim_noun_chunk'], list):\n",
    "        continue\n",
    "    # Check if 'keywords_yake_claims' column is an empty list or contains only empty lists\n",
    "    if not any(keyword for keyword in row['keywords_yake_claim_noun_chunk']):\n",
    "        continue\n",
    "    # Iterate over keywords in 'keywords_yake_claims' column and append to keywords_list_ep, consider only top 10 keywords\n",
    "    else:\n",
    "        for keyword in row['keywords_yake_claim_noun_chunk'][:10]:\n",
    "            # if keyword[1] <= min_yake_conf:\n",
    "            keywords_list_ep.append(keyword[0].lower())\n",
    "            yake_conf_score_list.append(keyword[1])\n",
    "            publn_nr_list.append(row['publn_nr'])\n",
    "            cpc_symbol_list.append(row['cpc_class_symbol'])\n",
    "\n",
    "# Create new dataframe\n",
    "df_keywords_list_ep = pd.DataFrame({\n",
    "    'keyword_yake': keywords_list_ep,\n",
    "    'yake_conf_score': yake_conf_score_list,\n",
    "    'publn_nr': publn_nr_list,\n",
    "    'cpc_class_symbol': cpc_symbol_list,\n",
    "    'abs_frequency': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1724465/1724465 [00:01<00:00, 1227954.03it/s]\n",
      "100%|██████████| 1656469/1656469 [00:00<00:00, 2168903.25it/s]\n",
      "100%|██████████| 1656469/1656469 [00:01<00:00, 1066813.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-alphanumeric keywords\n",
    "df_keywords_list_ep = df_keywords_list_ep[\n",
    "    df_keywords_list_ep['keyword_yake'].progress_apply(lambda x: all(word.isalnum() for word in x.split()))\n",
    "]\n",
    "\n",
    "# Filter out all keywords shorter than 3 characters\n",
    "df_keywords_list_ep = df_keywords_list_ep[\n",
    "    df_keywords_list_ep['keyword_yake'].progress_apply(lambda x: len(x) > 2)\n",
    "]\n",
    "\n",
    "# Define a function to check if a string is an abbreviation\n",
    "def is_abbreviation(keyword):\n",
    "    # Regular expression to identify abbreviations (typically all uppercase and periods)\n",
    "    # and check for all-uppercase abbreviations with 3 or fewer characters\n",
    "    pattern = re.compile(r'\\b(?:[A-Z]{1,}\\.){2,}\\b|\\b[A-Z]{1,3}\\b')\n",
    "    return pattern.match(keyword) is not None\n",
    "\n",
    "# Apply the function to filter out abbreviations\n",
    "df_keywords_list_ep = df_keywords_list_ep[\n",
    "    df_keywords_list_ep['keyword_yake'].progress_apply(lambda x: not is_abbreviation(x))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656469/1656469 [00:07<00:00, 234884.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize keywords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_keywords(keyword):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in keyword.split()])\n",
    "\n",
    "df_keywords_list_ep['keyword_yake_lemma'] = df_keywords_list_ep['keyword_yake'].progress_apply(lemmatize_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656469/1656469 [00:01<00:00, 1557196.21it/s]\n",
      "100%|██████████| 1656469/1656469 [00:00<00:00, 2379232.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Function to remove keywords that are only one stopword or start/end with a stopword\n",
    "def remove_stopwords(keyword):\n",
    "    words = keyword.split()\n",
    "    \n",
    "    # If the keyword is a single stopword, remove it\n",
    "    if len(words) == 1 and words[0] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    # If the keyword starts or ends with a stopword, remove line\n",
    "    if words[0] in stopwords:\n",
    "        return ''\n",
    "    if words and words[-1] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the function to remove stopwords\n",
    "df_keywords_list_ep['keyword_yake_lemma'] = df_keywords_list_ep['keyword_yake_lemma'].progress_apply(remove_stopwords)\n",
    "\n",
    "# Remove empty keywords\n",
    "df_keywords_list_ep = df_keywords_list_ep[\n",
    "    df_keywords_list_ep['keyword_yake_lemma'].progress_apply(lambda x: len(x) > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 333010/333010 [00:01<00:00, 197146.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate df_keywords_list_ep by 'keyword'\n",
    "df_keywords_list_ep_agg = df_keywords_list_ep.groupby(['keyword_yake_lemma']).agg({\n",
    "    'yake_conf_score': 'mean',\n",
    "    'publn_nr': list,\n",
    "    'cpc_class_symbol': list,\n",
    "    'abs_frequency': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten nested lists in 'cpc_class_symbol' column\n",
    "df_keywords_list_ep_agg['cpc_class_symbol'] = df_keywords_list_ep_agg['cpc_class_symbol'].progress_apply(lambda x: [item for sublist in x for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_list_ep_agg.to_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/epo_yake_keywords_list_noun_chunks.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_yake_claims_uspto = pd.read_json('/mnt/hdd01/patentsview/Patentsview - Cleantech Patents/g_patent_claims_cleantech_yake_noun_chunks.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "515742it [00:23, 21936.79it/s]\n"
     ]
    }
   ],
   "source": [
    "keywords_list_uspto = []\n",
    "yake_conf_score_list = []\n",
    "patent_id_list = []\n",
    "# min_yake_conf = 0.05 - Currently not used\n",
    "\n",
    "# Iterate over rows in dataframe\n",
    "for index, row in tqdm(df_yake_claims_uspto.iterrows()):\n",
    "    # Check if 'keywords_yake' column is not a list\n",
    "    if not isinstance(row['keywords_yake_claim_noun_chunk'], list):\n",
    "        continue\n",
    "    # Check if 'keywords_yake' column is an empty list or contains only empty lists\n",
    "    if not any(keyword for keyword in row['keywords_yake_claim_noun_chunk']):\n",
    "        continue\n",
    "    # Iterate over keywords in 'keywords_yake' column and append to keywords_list_uspto\n",
    "    else:\n",
    "        for keyword in row['keywords_yake_claim_noun_chunk'][:10]:\n",
    "            # if keyword[1] <= min_yake_conf:\n",
    "            keywords_list_uspto.append(keyword[0].lower())\n",
    "            yake_conf_score_list.append(keyword[1])\n",
    "            patent_id_list.append(row['patent_id'])\n",
    "\n",
    "# Create new dataframe\n",
    "df_keywords_list_uspto = pd.DataFrame({\n",
    "    'keyword_yake': keywords_list_uspto,\n",
    "    'yake_conf_score': yake_conf_score_list,\n",
    "    'patent_id': patent_id_list,\n",
    "    'abs_frequency': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5115943/5115943 [00:04<00:00, 1278048.31it/s]\n",
      "100%|██████████| 4935785/4935785 [00:02<00:00, 2363758.56it/s]\n",
      "100%|██████████| 4935785/4935785 [00:04<00:00, 1109943.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-alphanumeric keywords\n",
    "df_keywords_list_uspto = df_keywords_list_uspto[\n",
    "    df_keywords_list_uspto['keyword_yake'].progress_apply(lambda x: all(word.isalnum() for word in x.split()))\n",
    "]\n",
    "\n",
    "# Filter out all keywords shorter than 3 characters\n",
    "df_keywords_list_uspto = df_keywords_list_uspto[\n",
    "    df_keywords_list_uspto['keyword_yake'].progress_apply(lambda x: len(x) > 2)\n",
    "]\n",
    "\n",
    "# Define a function to check if a string is an abbreviation\n",
    "def is_abbreviation(keyword):\n",
    "    # Regular expression to identify abbreviations (typically all uppercase and periods)\n",
    "    # and check for all-uppercase abbreviations with 3 or fewer characters\n",
    "    pattern = re.compile(r'\\b(?:[A-Z]{1,}\\.){2,}\\b|\\b[A-Z]{1,3}\\b')\n",
    "    return pattern.match(keyword) is not None\n",
    "\n",
    "# Apply the function to filter out abbreviations\n",
    "df_keywords_list_uspto = df_keywords_list_uspto[\n",
    "    df_keywords_list_uspto['keyword_yake'].progress_apply(lambda x: not is_abbreviation(x))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Patents to CPC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 515745/515745 [00:00<00:00, 925507.84it/s]\n",
      "100%|██████████| 515745/515745 [00:00<00:00, 1190762.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# PatentsView - Merge with CPC Classification\n",
    "df_cpc_uspto = pd.read_json('/mnt/hdd01/patentsview/Patentsview - Cleantech Patents/df_patentsview_patent_cpc_grouped_cleantech.json')\n",
    "# Extract 'cpc_group' into a new column\n",
    "df_cpc_uspto['cpc_group'] = df_cpc_uspto['cpc'].progress_apply(\n",
    "    lambda x: [entry['cpc_group'] for entry in x.values() if 'cpc_group' in entry]\n",
    ")\n",
    "\n",
    "# Remove duplicates from 'cpc_group_list'\n",
    "df_cpc_uspto['cpc_group'] = df_cpc_uspto['cpc_group'].progress_apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_keywords_list_uspto with df_cpc_uspto\n",
    "df_keywords_list_uspto = pd.merge(\n",
    "    df_keywords_list_uspto,\n",
    "    df_cpc_uspto[['patent_id', 'cpc_group']],\n",
    "    how='left',\n",
    "    on='patent_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4935785/4935785 [00:19<00:00, 251958.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize keywords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_keywords(keyword):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in keyword.split()])\n",
    "\n",
    "df_keywords_list_uspto['keyword_yake_lemma'] = df_keywords_list_uspto['keyword_yake'].progress_apply(lemmatize_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4935785/4935785 [00:03<00:00, 1570873.43it/s]\n",
      "100%|██████████| 4935785/4935785 [00:02<00:00, 2349589.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Function to remove keywords that are only one stopword or start/end with a stopword\n",
    "def remove_stopwords(keyword):\n",
    "    words = keyword.split()\n",
    "    \n",
    "    # If the keyword is a single stopword, remove it\n",
    "    if len(words) == 1 and words[0] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    # If the keyword starts or ends with a stopword, remove line\n",
    "    if words[0] in stopwords:\n",
    "        return ''\n",
    "    if words and words[-1] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the function to remove stopwords\n",
    "df_keywords_list_uspto['keyword_yake_lemma'] = df_keywords_list_uspto['keyword_yake_lemma'].progress_apply(remove_stopwords)\n",
    "\n",
    "# Remove empty keywords\n",
    "df_keywords_list_uspto = df_keywords_list_uspto[\n",
    "    df_keywords_list_uspto['keyword_yake_lemma'].progress_apply(lambda x: len(x) > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 724045/724045 [00:07<00:00, 94066.54it/s] \n"
     ]
    }
   ],
   "source": [
    "# Aggregate df_keywords_list_ep by 'keyword'\n",
    "df_keywords_list_uspto_agg = df_keywords_list_uspto.groupby(['keyword_yake_lemma']).agg({\n",
    "    'yake_conf_score': 'mean',\n",
    "    'patent_id': list,\n",
    "    'cpc_group': list,\n",
    "    'abs_frequency': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten nested lists in 'cpc_group' column\n",
    "df_keywords_list_uspto_agg['cpc_group'] = df_keywords_list_uspto_agg['cpc_group'].progress_apply(lambda x: [item for sublist in x for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_list_uspto_agg.to_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/uspto_yake_keywords_list_noun_chunks.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliance on Science - USPTO and EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_rel_on_science_uspto = pd.read_json('/mnt/hdd01/patentsview/Reliance on Science - Cleantech Patents/df_oaid_Cleantech_y02_individual_works_yake_noun_chunks.json', dtype={'patent_id': str, 'oaid': str})\n",
    "df_rel_on_science_ep = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/Reliance on Science/cleantech_epo_rel_on_science_abstract_yake_noun_chunks.json', dtype={'publn_nr': str, 'oaid': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes, reset index and drop duplicates\n",
    "df_rel_on_science = pd.concat([df_rel_on_science_uspto, df_rel_on_science_ep], ignore_index=True)\n",
    "df_rel_on_science = df_rel_on_science.drop_duplicates(subset=['oaid'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "623364it [00:43, 14454.38it/s]\n"
     ]
    }
   ],
   "source": [
    "keywords_list_rel = []\n",
    "yake_conf_score_list = []\n",
    "oaid_list = []\n",
    "publn_nr_list = []\n",
    "patent_id_list = []\n",
    "# min_yake_conf = 0.05 - Currently not used\n",
    "\n",
    "# Iterate over rows in dataframe\n",
    "for index, row in tqdm(df_rel_on_science.iterrows()):\n",
    "    # Check if 'keywords_yake' column is not a list\n",
    "    if not isinstance(row['keywords_yake_abstract_noun_chunk'], list):\n",
    "        continue\n",
    "    # Check if 'keywords_yake' column is an empty list or contains only empty lists\n",
    "    if not any(keyword for keyword in row['keywords_yake_abstract_noun_chunk']):\n",
    "        continue\n",
    "    # Iterate over keywords in 'keywords_yake' column and append to keywords_list_rel\n",
    "    else:\n",
    "        for keyword in row['keywords_yake_abstract_noun_chunk'][:10]:\n",
    "            # if keyword[1] <= min_yake_conf:\n",
    "            keywords_list_rel.append(keyword[0].lower())\n",
    "            yake_conf_score_list.append(keyword[1])\n",
    "            oaid_list.append(row['oaid'])\n",
    "            publn_nr_list.append(row['publn_nr'])\n",
    "            patent_id_list.append(row['patent_id'])\n",
    "\n",
    "# Create new dataframe\n",
    "df_keywords_list_rel = pd.DataFrame({\n",
    "    'keyword_yake': keywords_list_rel,\n",
    "    'yake_conf_score': yake_conf_score_list,\n",
    "    'oaid': oaid_list,\n",
    "    'abs_frequency': 1,\n",
    "    'publn_nr': publn_nr_list,\n",
    "    'patent_id': patent_id_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6002161/6002161 [00:04<00:00, 1290900.60it/s]\n",
      "100%|██████████| 5526239/5526239 [00:02<00:00, 2536599.00it/s]\n",
      "100%|██████████| 5526239/5526239 [00:04<00:00, 1114949.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-alphanumeric keywords\n",
    "df_keywords_list_rel = df_keywords_list_rel[\n",
    "    df_keywords_list_rel['keyword_yake'].progress_apply(lambda x: all(word.isalnum() for word in x.split()))\n",
    "]\n",
    "\n",
    "# Filter out all keywords shorter than 3 characters\n",
    "df_keywords_list_rel = df_keywords_list_rel[\n",
    "    df_keywords_list_rel['keyword_yake'].progress_apply(lambda x: len(x) > 2)\n",
    "]\n",
    "\n",
    "# Define a function to check if a string is an abbreviation\n",
    "def is_abbreviation(keyword):\n",
    "    # Regular expression to identify abbreviations (typically all uppercase and periods)\n",
    "    # and check for all-uppercase abbreviations with 3 or fewer characters\n",
    "    pattern = re.compile(r'\\b(?:[A-Z]{1,}\\.){2,}\\b|\\b[A-Z]{1,3}\\b')\n",
    "    return pattern.match(keyword) is not None\n",
    "\n",
    "# Apply the function to filter out abbreviations\n",
    "df_keywords_list_rel = df_keywords_list_rel[\n",
    "    df_keywords_list_rel['keyword_yake'].progress_apply(lambda x: not is_abbreviation(x))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5526239/5526239 [00:22<00:00, 244526.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize keywords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_keywords(keyword):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in keyword.split()])\n",
    "\n",
    "df_keywords_list_rel['keyword_yake_lemma'] = df_keywords_list_rel['keyword_yake'].progress_apply(lemmatize_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5526239/5526239 [00:03<00:00, 1639468.80it/s]\n",
      "100%|██████████| 5526239/5526239 [00:02<00:00, 2586973.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Function to remove keywords that are only one stopword or start/end with a stopword\n",
    "def remove_stopwords(keyword):\n",
    "    words = keyword.split()\n",
    "    \n",
    "    # If the keyword is a single stopword, remove it\n",
    "    if len(words) == 1 and words[0] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    # If the keyword starts or ends with a stopword, remove line\n",
    "    if words[0] in stopwords:\n",
    "        return ''\n",
    "    if words and words[-1] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the function to remove stopwords\n",
    "df_keywords_list_rel['keyword_yake_lemma'] = df_keywords_list_rel['keyword_yake_lemma'].progress_apply(remove_stopwords)\n",
    "\n",
    "# Remove empty keywords\n",
    "df_keywords_list_rel = df_keywords_list_rel[\n",
    "    df_keywords_list_rel['keyword_yake_lemma'].progress_apply(lambda x: len(x) > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5523351/5523351 [00:02<00:00, 2329283.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cast 'publn_nr' column to string\n",
    "df_keywords_list_rel['publn_nr'] = df_keywords_list_rel['publn_nr'].progress_apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1197878/1197878 [00:01<00:00, 775967.36it/s]\n",
      "100%|██████████| 1197878/1197878 [00:01<00:00, 803346.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate df_keywords_list_rel by 'keyword_yake_lemma'\n",
    "df_keywords_list_rel_agg = df_keywords_list_rel.groupby(['keyword_yake_lemma']).agg({\n",
    "    'yake_conf_score': 'mean',\n",
    "    'oaid': list,\n",
    "    'publn_nr': list,\n",
    "    'patent_id': list,\n",
    "    'abs_frequency': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "# Delete all nan list entries in columns 'publn_nr' and 'patent_id'\n",
    "df_keywords_list_rel_agg['publn_nr'] = df_keywords_list_rel_agg['publn_nr'].progress_apply(lambda x: [item for item in x if str(item) != 'nan'])\n",
    "df_keywords_list_rel_agg['patent_id'] = df_keywords_list_rel_agg['patent_id'].progress_apply(lambda x: [item for item in x if str(item) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "      <th>yake_conf_score</th>\n",
       "      <th>oaid</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>abs_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078296</th>\n",
       "      <td>testing device</td>\n",
       "      <td>0.084503</td>\n",
       "      <td>[1979508045]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[9643711]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>abstract loading</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>[2161400967]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[7608557]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125436</th>\n",
       "      <td>umfasst</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>[4244532323]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[8865359]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901231</th>\n",
       "      <td>recently characterized depsipeptide</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>[2070072813]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[10494407]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794140</th>\n",
       "      <td>peptidalkaloide wurde zunächst</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>[2109103725]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[7582604]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121456</th>\n",
       "      <td>bond representative carbon</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>[1556512819]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[10960087]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917544</th>\n",
       "      <td>renally impaired patient</td>\n",
       "      <td>0.100391</td>\n",
       "      <td>[2165011987, 1802548550]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[11022593, 7213009]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766223</th>\n",
       "      <td>organ selectivity</td>\n",
       "      <td>0.112657</td>\n",
       "      <td>[2066283662]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[7452538]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019378</th>\n",
       "      <td>squid</td>\n",
       "      <td>0.170053</td>\n",
       "      <td>[2151810181, 2067349649, 2076275236, 949100985...</td>\n",
       "      <td>[['1909061'], ['0496530', '0487130'], ['371839...</td>\n",
       "      <td>[10695062, 9512899, 6472541, 10277208, 9219978...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592919</th>\n",
       "      <td>laser gas heating</td>\n",
       "      <td>0.018877</td>\n",
       "      <td>[2021119433]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[9609732]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413711</th>\n",
       "      <td>fundamental genetic fault</td>\n",
       "      <td>0.076856</td>\n",
       "      <td>[2013960456]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[7217807]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942724</th>\n",
       "      <td>safety consideration</td>\n",
       "      <td>0.243279</td>\n",
       "      <td>[2081412807, 1657997729]</td>\n",
       "      <td>[['0876143', '0876143']]</td>\n",
       "      <td>[5818649]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373889</th>\n",
       "      <td>facing frd enzyme</td>\n",
       "      <td>0.077668</td>\n",
       "      <td>[2127347515]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[11041176]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185075</th>\n",
       "      <td>yispwilav</td>\n",
       "      <td>0.167071</td>\n",
       "      <td>[2149390157, 2979601799]</td>\n",
       "      <td>[['2300034', '2300034']]</td>\n",
       "      <td>[11083783]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164535</th>\n",
       "      <td>chemical inducer dimethyl</td>\n",
       "      <td>0.111488</td>\n",
       "      <td>[1792794566]</td>\n",
       "      <td>[['0454781', '0832980', '0832980']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          keyword_yake_lemma  yake_conf_score  \\\n",
       "1078296                       testing device         0.084503   \n",
       "7789                        abstract loading         0.009040   \n",
       "1125436                              umfasst         0.151127   \n",
       "901231   recently characterized depsipeptide         0.001241   \n",
       "794140        peptidalkaloide wurde zunächst         0.006159   \n",
       "121456            bond representative carbon         0.000112   \n",
       "917544              renally impaired patient         0.100391   \n",
       "766223                     organ selectivity         0.112657   \n",
       "1019378                                squid         0.170053   \n",
       "592919                     laser gas heating         0.018877   \n",
       "413711             fundamental genetic fault         0.076856   \n",
       "942724                  safety consideration         0.243279   \n",
       "373889                     facing frd enzyme         0.077668   \n",
       "1185075                            yispwilav         0.167071   \n",
       "164535             chemical inducer dimethyl         0.111488   \n",
       "\n",
       "                                                      oaid  \\\n",
       "1078296                                       [1979508045]   \n",
       "7789                                          [2161400967]   \n",
       "1125436                                       [4244532323]   \n",
       "901231                                        [2070072813]   \n",
       "794140                                        [2109103725]   \n",
       "121456                                        [1556512819]   \n",
       "917544                            [2165011987, 1802548550]   \n",
       "766223                                        [2066283662]   \n",
       "1019378  [2151810181, 2067349649, 2076275236, 949100985...   \n",
       "592919                                        [2021119433]   \n",
       "413711                                        [2013960456]   \n",
       "942724                            [2081412807, 1657997729]   \n",
       "373889                                        [2127347515]   \n",
       "1185075                           [2149390157, 2979601799]   \n",
       "164535                                        [1792794566]   \n",
       "\n",
       "                                                  publn_nr  \\\n",
       "1078296                                                 []   \n",
       "7789                                                    []   \n",
       "1125436                                                 []   \n",
       "901231                                                  []   \n",
       "794140                                                  []   \n",
       "121456                                                  []   \n",
       "917544                                                  []   \n",
       "766223                                                  []   \n",
       "1019378  [['1909061'], ['0496530', '0487130'], ['371839...   \n",
       "592919                                                  []   \n",
       "413711                                                  []   \n",
       "942724                            [['0876143', '0876143']]   \n",
       "373889                                                  []   \n",
       "1185075                           [['2300034', '2300034']]   \n",
       "164535                 [['0454781', '0832980', '0832980']]   \n",
       "\n",
       "                                                 patent_id  abs_frequency  \n",
       "1078296                                          [9643711]              1  \n",
       "7789                                             [7608557]              1  \n",
       "1125436                                          [8865359]              1  \n",
       "901231                                          [10494407]              1  \n",
       "794140                                           [7582604]              1  \n",
       "121456                                          [10960087]              1  \n",
       "917544                                 [11022593, 7213009]              2  \n",
       "766223                                           [7452538]              1  \n",
       "1019378  [10695062, 9512899, 6472541, 10277208, 9219978...             40  \n",
       "592919                                           [9609732]              1  \n",
       "413711                                           [7217807]              1  \n",
       "942724                                           [5818649]              2  \n",
       "373889                                          [11041176]              1  \n",
       "1185075                                         [11083783]              2  \n",
       "164535                                                  []              1  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_list_rel_agg.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_list_rel_agg.to_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/rel_on_science_yake_keywords_list_noun_chunks.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpc_classification = pd.read_json('/mnt/hdd01/patentsview/CPC Classification/df_keyword_y02_classification_noun_chunking.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpc_classification</th>\n",
       "      <th>sequence</th>\n",
       "      <th>title</th>\n",
       "      <th>title_lower</th>\n",
       "      <th>full_title</th>\n",
       "      <th>keywords_yake_title_lower</th>\n",
       "      <th>keywords_yake_title_lower_noun_chunk</th>\n",
       "      <th>noun_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y02</td>\n",
       "      <td>-2</td>\n",
       "      <td>Technologies or applications for mitigation or...</td>\n",
       "      <td>technologies or applications for mitigation or...</td>\n",
       "      <td>Technologies or applications for mitigation or...</td>\n",
       "      <td>[[technologies or applications, 0.0], [climate...</td>\n",
       "      <td>[[climate change, 0.0153808212], [mitigation, ...</td>\n",
       "      <td>[mitigation, climate change, applications, ada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cpc_classification  sequence  \\\n",
       "0                Y02        -2   \n",
       "\n",
       "                                               title  \\\n",
       "0  Technologies or applications for mitigation or...   \n",
       "\n",
       "                                         title_lower  \\\n",
       "0  technologies or applications for mitigation or...   \n",
       "\n",
       "                                          full_title  \\\n",
       "0  Technologies or applications for mitigation or...   \n",
       "\n",
       "                           keywords_yake_title_lower  \\\n",
       "0  [[technologies or applications, 0.0], [climate...   \n",
       "\n",
       "                keywords_yake_title_lower_noun_chunk  \\\n",
       "0  [[climate change, 0.0153808212], [mitigation, ...   \n",
       "\n",
       "                                         noun_chunks  \n",
       "0  [mitigation, climate change, applications, ada...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cpc_classification.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [00:00, 11339.11it/s]\n"
     ]
    }
   ],
   "source": [
    "keywords_list_cpc = []\n",
    "yake_conf_score_list = []\n",
    "cpc_symbol_list = []\n",
    "# min_yake_conf = 0.05 - Currently not used\n",
    "\n",
    "# Iterate over rows in dataframe\n",
    "for index, row in tqdm(df_cpc_classification.iterrows()):\n",
    "    # Check if 'keywords_yake_claims' column is not a list\n",
    "    if not isinstance(row['keywords_yake_title_lower_noun_chunk'], list):\n",
    "        continue\n",
    "    # Check if 'keywords_yake_claims' column is an empty list or contains only empty lists\n",
    "    if not any(keyword for keyword in row['keywords_yake_title_lower_noun_chunk']):\n",
    "        continue\n",
    "    # Iterate over keywords in 'keywords_yake_claims' column and append to keywords_list_ep, consider only top 10 keywords\n",
    "    else:\n",
    "        for keyword in row['keywords_yake_title_lower_noun_chunk'][:10]:\n",
    "            # if keyword[1] <= min_yake_conf:\n",
    "            keywords_list_cpc.append(keyword[0].lower())\n",
    "            yake_conf_score_list.append(keyword[1])\n",
    "            cpc_symbol_list.append(row['cpc_classification'])\n",
    "\n",
    "# Create new dataframe\n",
    "df_keywords_list_cpc = pd.DataFrame({\n",
    "    'keyword_yake': keywords_list_cpc,\n",
    "    'yake_conf_score': yake_conf_score_list,\n",
    "    'cpc_class_symbol': cpc_symbol_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 707/707 [00:00<00:00, 381300.36it/s]\n",
      "100%|██████████| 672/672 [00:00<00:00, 706940.63it/s]\n",
      "100%|██████████| 672/672 [00:00<00:00, 347243.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-alphanumeric keywords\n",
    "df_keywords_list_cpc = df_keywords_list_cpc[\n",
    "    df_keywords_list_cpc['keyword_yake'].progress_apply(lambda x: all(word.isalnum() for word in x.split()))\n",
    "]\n",
    "\n",
    "# Filter out all keywords shorter than 3 characters\n",
    "df_keywords_list_cpc = df_keywords_list_cpc[\n",
    "    df_keywords_list_cpc['keyword_yake'].progress_apply(lambda x: len(x) > 2)\n",
    "]\n",
    "\n",
    "# Define a function to check if a string is an abbreviation\n",
    "def is_abbreviation(keyword):\n",
    "    # Regular expression to identify abbreviations (typically all uppercase and periods)\n",
    "    # and check for all-uppercase abbreviations with 3 or fewer characters\n",
    "    pattern = re.compile(r'\\b(?:[A-Z]{1,}\\.){2,}\\b|\\b[A-Z]{1,3}\\b')\n",
    "    return pattern.match(keyword) is not None\n",
    "\n",
    "# Apply the function to filter out abbreviations\n",
    "df_keywords_list_cpc = df_keywords_list_cpc[\n",
    "    df_keywords_list_cpc['keyword_yake'].progress_apply(lambda x: not is_abbreviation(x))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 672/672 [00:00<00:00, 930.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize keywords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_keywords(keyword):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in keyword.split()])\n",
    "\n",
    "df_keywords_list_cpc['keyword_yake_lemma'] = df_keywords_list_cpc['keyword_yake'].progress_apply(lemmatize_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 672/672 [00:00<00:00, 780984.29it/s]\n",
      "100%|██████████| 672/672 [00:00<00:00, 1261106.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Function to remove keywords that are only one stopword or start/end with a stopword\n",
    "def remove_stopwords(keyword):\n",
    "    words = keyword.split()\n",
    "    \n",
    "    # If the keyword is a single stopword, remove it\n",
    "    if len(words) == 1 and words[0] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    # If the keyword starts or ends with a stopword, remove line\n",
    "    if words[0] in stopwords:\n",
    "        return ''\n",
    "    if words and words[-1] in stopwords:\n",
    "        return ''\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the function to remove stopwords\n",
    "df_keywords_list_cpc['keyword_yake_lemma'] = df_keywords_list_cpc['keyword_yake_lemma'].progress_apply(remove_stopwords)\n",
    "\n",
    "# Remove empty keywords\n",
    "df_keywords_list_cpc = df_keywords_list_cpc[\n",
    "    df_keywords_list_cpc['keyword_yake_lemma'].progress_apply(lambda x: len(x) > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_yake</th>\n",
       "      <th>yake_conf_score</th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate change</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>Y02</td>\n",
       "      <td>climate change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword_yake  yake_conf_score cpc_class_symbol keyword_yake_lemma\n",
       "0  climate change         0.015381              Y02     climate change"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_list_cpc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate df_keywords_list_cpc by 'keyword'\n",
    "df_keywords_list_cpc_agg = df_keywords_list_cpc.groupby(['keyword_yake_lemma']).agg({\n",
    "    'yake_conf_score': 'mean',\n",
    "    'cpc_class_symbol': list,\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_list_cpc_agg.to_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge EP, USPTO and Reliance on Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_keywords_list_uspto_agg = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/uspto_yake_keywords_list_noun_chunks.json')\n",
    "df_keywords_list_ep_agg = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/epo_yake_keywords_list_noun_chunks.json')\n",
    "df_keywords_list_rel_agg = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/rel_on_science_yake_keywords_list_noun_chunks.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 333010/333010 [00:03<00:00, 85829.38it/s] \n",
      "100%|██████████| 724045/724045 [00:01<00:00, 700259.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Cast publn_nr and patent_id to list of strings\n",
    "df_keywords_list_ep_agg['publn_nr'] = df_keywords_list_ep_agg['publn_nr'].progress_apply(lambda x: [str(item) for item in x])\n",
    "df_keywords_list_uspto_agg['patent_id'] = df_keywords_list_uspto_agg['patent_id'].progress_apply(lambda x: [str(item) for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_keywords_list_uspto_agg, df_keywords_list_ep_agg, df_keywords_list_rel_agg]\n",
    "df_keywords_list = pd.concat(frames)\n",
    "df_keywords_list.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "      <th>yake_conf_score</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>cpc_group</th>\n",
       "      <th>abs_frequency</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "      <th>oaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958791</th>\n",
       "      <td>principal</td>\n",
       "      <td>0.069415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>[130483, 145557, 211084, 280762, 580790, 65402...</td>\n",
       "      <td>[Y02E  30/30, Y02P  70/50, Y02E  60/50, Y02P  ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424744</th>\n",
       "      <td>expression vector family</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>[7323619]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2136646494]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673822</th>\n",
       "      <td>triangular shaped die</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>[4889476]</td>\n",
       "      <td>[Y02P40/57]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706296</th>\n",
       "      <td>voltage variance</td>\n",
       "      <td>0.026912</td>\n",
       "      <td>[10052968, 7019489]</td>\n",
       "      <td>[Y02T10/70, Y02E60/50, Y02T90/40, Y02T10/70]</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266155</th>\n",
       "      <td>functional processor</td>\n",
       "      <td>0.037849</td>\n",
       "      <td>[9626220]</td>\n",
       "      <td>[Y02D10/00]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword_yake_lemma  yake_conf_score            patent_id  \\\n",
       "958791                  principal         0.069415                  NaN   \n",
       "1424744  expression vector family         0.039519            [7323619]   \n",
       "673822      triangular shaped die         0.011013            [4889476]   \n",
       "706296           voltage variance         0.026912  [10052968, 7019489]   \n",
       "266155       functional processor         0.037849            [9626220]   \n",
       "\n",
       "                                            cpc_group  abs_frequency  \\\n",
       "958791                                            NaN             37   \n",
       "1424744                                           NaN              1   \n",
       "673822                                    [Y02P40/57]              1   \n",
       "706296   [Y02T10/70, Y02E60/50, Y02T90/40, Y02T10/70]              2   \n",
       "266155                                    [Y02D10/00]              1   \n",
       "\n",
       "                                                  publn_nr  \\\n",
       "958791   [130483, 145557, 211084, 280762, 580790, 65402...   \n",
       "1424744                                                 []   \n",
       "673822                                                 NaN   \n",
       "706296                                                 NaN   \n",
       "266155                                                 NaN   \n",
       "\n",
       "                                          cpc_class_symbol          oaid  \n",
       "958791   [Y02E  30/30, Y02P  70/50, Y02E  60/50, Y02P  ...           NaN  \n",
       "1424744                                                NaN  [2136646494]  \n",
       "673822                                                 NaN           NaN  \n",
       "706296                                                 NaN           NaN  \n",
       "266155                                                 NaN           NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_list.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_lists(series):\n",
    "    combined_list = []\n",
    "    for item in series:\n",
    "        if isinstance(item, list):\n",
    "            combined_list.extend(item)\n",
    "    return combined_list\n",
    "\n",
    "# Group by 'keyword_yake_lemma' and aggregate\n",
    "df_keywords_list_agg = df_keywords_list.groupby('keyword_yake_lemma').agg({\n",
    "    'yake_conf_score': 'mean',        # Mean of yake_conf_score\n",
    "    'abs_frequency': 'sum',           # Sum of abs_frequency\n",
    "    'patent_id': concat_lists,        # Concatenate lists in patent_id\n",
    "    'publn_nr': concat_lists,         # Concatenate lists in publn_nr\n",
    "    'oaid': concat_lists,             # Concatenate lists in oaid\n",
    "    'cpc_group': concat_lists,        # Concatenate lists in cpc_group\n",
    "    'cpc_class_symbol': concat_lists  # Concatenate lists in cpc_class_symbol\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1961759/1961759 [00:02<00:00, 783131.25it/s]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def flatten_and_convert(entry):\n",
    "    # If the entry is NaN (float type in pandas), return an empty list\n",
    "    if isinstance(entry, float):\n",
    "        return []\n",
    "\n",
    "    # Initialize an empty list to store the flattened results\n",
    "    flattened_list = []\n",
    "\n",
    "    # Check if the entry is a string and convert it to a list if it represents a list\n",
    "    if isinstance(entry, str) and entry.startswith(\"[\") and entry.endswith(\"]\"):\n",
    "        try:\n",
    "            entry = ast.literal_eval(entry)\n",
    "        except ValueError:\n",
    "            # If conversion fails, return an empty list\n",
    "            return []\n",
    "\n",
    "    # If the entry is a list, process its items\n",
    "    if isinstance(entry, list):\n",
    "        for item in entry:\n",
    "            # If the item is a string representation of a list, convert it\n",
    "            if isinstance(item, str) and item.startswith(\"[\") and item.endswith(\"]\"):\n",
    "                try:\n",
    "                    item = ast.literal_eval(item)\n",
    "                except ValueError:\n",
    "                    continue  # Skip items that can't be converted\n",
    "\n",
    "            # If the item is a list, extend the flattened list with its elements\n",
    "            if isinstance(item, list):\n",
    "                flattened_list.extend(item)\n",
    "            else:\n",
    "                # For single string items, append them directly\n",
    "                flattened_list.append(item)\n",
    "\n",
    "    return flattened_list\n",
    "\n",
    "# Apply the function to the 'publn_nr' column\n",
    "df_keywords_list_agg['publn_nr'] = df_keywords_list_agg['publn_nr'].progress_apply(flatten_and_convert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1961759/1961759 [00:01<00:00, 1008155.66it/s]\n",
      "100%|██████████| 1961759/1961759 [00:01<00:00, 1612314.25it/s]\n",
      "100%|██████████| 1961759/1961759 [00:07<00:00, 273363.51it/s] \n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(lst):\n",
    "    # Convert list to set to remove duplicates, then back to list\n",
    "    return list(set(lst))\n",
    "\n",
    "# Apply the function to each relevant column\n",
    "df_keywords_list_agg['patent_id'] = df_keywords_list_agg['patent_id'].progress_apply(remove_duplicates)\n",
    "df_keywords_list_agg['publn_nr'] = df_keywords_list_agg['publn_nr'].progress_apply(remove_duplicates)\n",
    "df_keywords_list_agg['oaid'] = df_keywords_list_agg['oaid'].progress_apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1961759/1961759 [00:01<00:00, 1161631.03it/s]\n",
      "100%|██████████| 1961759/1961759 [00:02<00:00, 927183.99it/s]\n",
      "100%|██████████| 1961759/1961759 [00:01<00:00, 1511009.37it/s]\n",
      "100%|██████████| 1961759/1961759 [00:07<00:00, 251310.94it/s] \n",
      "100%|██████████| 1961759/1961759 [00:01<00:00, 1594885.80it/s]\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates_from_lists(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].progress_apply(lambda x: list(set(x)))\n",
    "    return df\n",
    "\n",
    "# Apply this function to the 'oaid', 'patent_id', and 'publn_nr' columns\n",
    "df_keywords_list_agg = remove_duplicates_from_lists(df_keywords_list_agg, ['oaid', 'patent_id', 'publn_nr', 'cpc_group', 'cpc_class_symbol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune dataframe by document frequency and absolute frequency\n",
    "min_abs_frequency = 5\n",
    "max_abs_frequency = 1000\n",
    "# max_doc_frequency = 0.3\n",
    "\n",
    "df_keywords_list_agg_pruned = df_keywords_list_agg[(df_keywords_list_agg['abs_frequency'] >= min_abs_frequency) & (df_keywords_list_agg['abs_frequency'] <= max_abs_frequency)]\n",
    "\n",
    "# Reset index\n",
    "df_keywords_list_agg_pruned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiesen/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/thiesen/.cache/torch/sentence_transformers/climatebert_distilroberta-base-climate-f. Creating a new one with MEAN pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /home/thiesen/.cache/torch/sentence_transformers/climatebert_distilroberta-base-climate-f and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "No sentence-transformers model found with name /home/thiesen/.cache/torch/sentence_transformers/anferico_bert-for-patents. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "model_climatebert = SentenceTransformer('climatebert/distilroberta-base-climate-f')\n",
    "model_bertforpatents = SentenceTransformer('anferico/bert-for-patents')\n",
    "model_patentsberta = SentenceTransformer('AI-Growth-Lab/PatentSBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: NVIDIA RTX A4500\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU available: {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151044/151044 [16:15<00:00, 154.81it/s]\n",
      "100%|██████████| 151044/151044 [09:49<00:00, 256.10it/s]\n",
      "100%|██████████| 151044/151044 [32:06<00:00, 78.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate copy of df_claims_keywords_list\n",
    "df_keywords_list_agg_embeddings = df_keywords_list_agg_pruned.copy()\n",
    "\n",
    "# Perform sentence embedding on the 'keyword_yake' (PatentsView) or 'keywords_yake_claims' (EPO) column\n",
    "df_keywords_list_agg_embeddings['keyword_yake_patentsberta_embedding'] = df_keywords_list_agg_embeddings['keyword_yake_lemma'].progress_apply(\n",
    "    lambda x: model_patentsberta.encode(x)\n",
    ")\n",
    "\n",
    "df_keywords_list_agg_embeddings['keyword_yake_climatebert_embedding'] = df_keywords_list_agg_embeddings['keyword_yake_lemma'].progress_apply(\n",
    "    lambda x: model_climatebert.encode(x)\n",
    ")\n",
    "\n",
    "df_keywords_list_agg_embeddings['keyword_yake_bertforpatents_embedding'] = df_keywords_list_agg_embeddings['keyword_yake_lemma'].progress_apply(\n",
    "    lambda x: model_bertforpatents.encode(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "      <th>yake_conf_score</th>\n",
       "      <th>abs_frequency</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>oaid</th>\n",
       "      <th>cpc_group</th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "      <th>keyword_yake_patentsberta_embedding</th>\n",
       "      <th>keyword_yake_climatebert_embedding</th>\n",
       "      <th>keyword_yake_bertforpatents_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52423</th>\n",
       "      <td>forming unit</td>\n",
       "      <td>0.116527</td>\n",
       "      <td>10</td>\n",
       "      <td>[11024867, 11013773, 10953053, 10696572, 10258...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2314723347, 2127724848, 2000754494, 216455397...</td>\n",
       "      <td>[Y02A50/30, Y02T10/72, Y02P70/50, Y02E60/10, Y...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.2664432, -0.71336854, -0.19560274, 0.12043...</td>\n",
       "      <td>[-0.04168712, -0.01022782, -0.0611551, 0.01770...</td>\n",
       "      <td>[0.45502183, -0.12699415, 0.23816243, -0.44813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53910</th>\n",
       "      <td>fuel property</td>\n",
       "      <td>0.041170</td>\n",
       "      <td>17</td>\n",
       "      <td>[8027781, 6109225, 7050901, 10113208, 6073611,...</td>\n",
       "      <td>[2778378, 2507495, 1517024]</td>\n",
       "      <td>[2170485159, 1969102714, 2089352982, 2094700891]</td>\n",
       "      <td>[Y02T10/12, Y02T10/40, Y02T10/30]</td>\n",
       "      <td>[Y02T  10/30]</td>\n",
       "      <td>[-0.36710405, -0.20286739, -0.29043177, 0.0753...</td>\n",
       "      <td>[-0.06109487, 0.07157007, -0.035822365, -0.114...</td>\n",
       "      <td>[-0.66123885, -0.11224864, -0.5386305, -0.1484...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58175</th>\n",
       "      <td>gramineae</td>\n",
       "      <td>0.062648</td>\n",
       "      <td>7</td>\n",
       "      <td>[8551758, 10226502, 8765438, 6331660, 6821782,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2054771403, 2077478467, 69996558, 2153702005,...</td>\n",
       "      <td>[Y02A40/146]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.071831, -0.38879472, -0.19552678, 0.319098...</td>\n",
       "      <td>[-0.10427654, -0.005826688, -0.026911682, 0.15...</td>\n",
       "      <td>[0.21785995, -0.5709935, 0.3596971, -0.9650602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67739</th>\n",
       "      <td>immunological reviewsvolume</td>\n",
       "      <td>0.033162</td>\n",
       "      <td>16</td>\n",
       "      <td>[7279462, 10190095, 6340459, 5843904, 8772257,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1998912267, 2141116067, 2085662422, 212531261...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.24936381, -0.40906265, -0.2253454, -0.16598...</td>\n",
       "      <td>[-0.04198655, 0.1732413, 0.07903323, -0.016652...</td>\n",
       "      <td>[-0.43490568, -0.5597404, 0.81100875, 0.517311...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39323</th>\n",
       "      <td>dvd player</td>\n",
       "      <td>0.104078</td>\n",
       "      <td>6</td>\n",
       "      <td>[6166496, 10228667, 11316056, 8091772, 7453832...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1681689143, 2046204174, 2011142855, 2023891690]</td>\n",
       "      <td>[Y02B20/30, Y02D30/70]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.0057602962, -0.64290005, -0.27191755, 0.10...</td>\n",
       "      <td>[-0.0021057706, 0.10024575, -0.017373513, 0.01...</td>\n",
       "      <td>[-0.4767, 0.1379464, 0.036986217, 0.11431643, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                keyword_yake_lemma  yake_conf_score  abs_frequency  \\\n",
       "52423                 forming unit         0.116527             10   \n",
       "53910                fuel property         0.041170             17   \n",
       "58175                    gramineae         0.062648              7   \n",
       "67739  immunological reviewsvolume         0.033162             16   \n",
       "39323                   dvd player         0.104078              6   \n",
       "\n",
       "                                               patent_id  \\\n",
       "52423  [11024867, 11013773, 10953053, 10696572, 10258...   \n",
       "53910  [8027781, 6109225, 7050901, 10113208, 6073611,...   \n",
       "58175  [8551758, 10226502, 8765438, 6331660, 6821782,...   \n",
       "67739  [7279462, 10190095, 6340459, 5843904, 8772257,...   \n",
       "39323  [6166496, 10228667, 11316056, 8091772, 7453832...   \n",
       "\n",
       "                          publn_nr  \\\n",
       "52423                           []   \n",
       "53910  [2778378, 2507495, 1517024]   \n",
       "58175                           []   \n",
       "67739                           []   \n",
       "39323                           []   \n",
       "\n",
       "                                                    oaid  \\\n",
       "52423  [2314723347, 2127724848, 2000754494, 216455397...   \n",
       "53910   [2170485159, 1969102714, 2089352982, 2094700891]   \n",
       "58175  [2054771403, 2077478467, 69996558, 2153702005,...   \n",
       "67739  [1998912267, 2141116067, 2085662422, 212531261...   \n",
       "39323   [1681689143, 2046204174, 2011142855, 2023891690]   \n",
       "\n",
       "                                               cpc_group cpc_class_symbol  \\\n",
       "52423  [Y02A50/30, Y02T10/72, Y02P70/50, Y02E60/10, Y...               []   \n",
       "53910                  [Y02T10/12, Y02T10/40, Y02T10/30]    [Y02T  10/30]   \n",
       "58175                                       [Y02A40/146]               []   \n",
       "67739                                                 []               []   \n",
       "39323                             [Y02B20/30, Y02D30/70]               []   \n",
       "\n",
       "                     keyword_yake_patentsberta_embedding  \\\n",
       "52423  [-0.2664432, -0.71336854, -0.19560274, 0.12043...   \n",
       "53910  [-0.36710405, -0.20286739, -0.29043177, 0.0753...   \n",
       "58175  [-0.071831, -0.38879472, -0.19552678, 0.319098...   \n",
       "67739  [0.24936381, -0.40906265, -0.2253454, -0.16598...   \n",
       "39323  [-0.0057602962, -0.64290005, -0.27191755, 0.10...   \n",
       "\n",
       "                      keyword_yake_climatebert_embedding  \\\n",
       "52423  [-0.04168712, -0.01022782, -0.0611551, 0.01770...   \n",
       "53910  [-0.06109487, 0.07157007, -0.035822365, -0.114...   \n",
       "58175  [-0.10427654, -0.005826688, -0.026911682, 0.15...   \n",
       "67739  [-0.04198655, 0.1732413, 0.07903323, -0.016652...   \n",
       "39323  [-0.0021057706, 0.10024575, -0.017373513, 0.01...   \n",
       "\n",
       "                   keyword_yake_bertforpatents_embedding  \n",
       "52423  [0.45502183, -0.12699415, 0.23816243, -0.44813...  \n",
       "53910  [-0.66123885, -0.11224864, -0.5386305, -0.1484...  \n",
       "58175  [0.21785995, -0.5709935, 0.3596971, -0.9650602...  \n",
       "67739  [-0.43490568, -0.5597404, 0.81100875, 0.517311...  \n",
       "39323  [-0.4767, 0.1379464, 0.036986217, 0.11431643, ...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_list_agg_embeddings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to json\n",
    "df_keywords_list_agg_embeddings.to_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_noun_chunks.json', orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
