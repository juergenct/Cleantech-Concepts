{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordtrie import WordTrie\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from multiprocessing import Pool\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lemmatize a single text\n",
    "def lemmatize_single_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    try:\n",
    "        word_list = text.split()\n",
    "        return ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "# Function to apply lemmatization over a series in a DataFrame\n",
    "def lemmatize_text(series, cores=12):\n",
    "    with Pool(cores) as pool:\n",
    "        return pool.map(lemmatize_single_text, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_keywords = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cleantech_keywords_similarity_015_co_occurrence_01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column cleantech_trie_count and non_cleantech_trie_count\n",
    "df_cleantech_keywords['cleantech_trie_count'] = 0\n",
    "df_cleantech_keywords['non_cleantech_trie_count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build WordTrie\n",
    "def make_wordtrie(keyword_list):\n",
    "    trie = WordTrie()\n",
    "    if keyword_list is None:\n",
    "        return None\n",
    "    i = 0\n",
    "    for keyword in keyword_list:\n",
    "        if isinstance(keyword, str):\n",
    "            trie.add(keyword, i)\n",
    "            i += 1\n",
    "    print(f\"Added {i} keywords to trie\")\n",
    "    return trie\n",
    "\n",
    "# Build WordTrie\n",
    "cleantech_trie = make_wordtrie(df_cleantech_keywords['keyword_yake_lemma'].tolist())\n",
    "non_cleantech_trie = make_wordtrie(df_cleantech_keywords['keyword_yake_lemma'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleantech Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_uspto = pd.read_json('/mnt/hdd01/patentsview/Patentsview - Cleantech Patents/g_patent_claims_cleantech_yake.json')\n",
    "# Lemmatize the claim_fulltext\n",
    "df_cleantech_uspto['claim_fulltext'] = lemmatize_text(df_cleantech_uspto['claim_fulltext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_uspto[\"trie\"] = df_cleantech_uspto[\"claim_fulltext\"].apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "df_cleantech_uspto[\"trie\"] = df_cleantech_uspto[\"trie\"].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_trie_explode = df_cleantech_uspto[\"trie\"].explode()\n",
    "df_cleantech_trie_explode = pd.DataFrame(df_cleantech_trie_explode).reset_index()\n",
    "df_cleantech_trie_count = df_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['cleantech_trie_count'] = df_cleantech_keywords['cleantech_trie_count'] + df_cleantech_keywords['cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_cleantech_trie_count\n",
    "del df_cleantech_trie_explode\n",
    "del df_cleantech_uspto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_epo = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/PATSTAT/cleantech_epo_text_data_pivot_cleaned.json')\n",
    "df_cleantech_epo['cleaned_claims'] = lemmatize_text(df_cleantech_epo['cleaned_claims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_epo['cleaned_claims'] = lemmatize_text(df_cleantech_epo['cleaned_claims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows where cleaned_claims is not a string\n",
    "df_cleantech_epo = df_cleantech_epo[df_cleantech_epo['cleaned_claims'].apply(lambda x: isinstance(x, str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_epo[\"trie\"] = df_cleantech_epo[\"cleaned_claims\"].apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "df_cleantech_epo[\"trie\"] = df_cleantech_epo[\"trie\"].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_trie_explode = df_cleantech_epo[\"trie\"].explode()\n",
    "df_cleantech_trie_explode = pd.DataFrame(df_cleantech_trie_explode).reset_index()\n",
    "df_cleantech_trie_count = df_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['cleantech_trie_count'] = df_cleantech_keywords['cleantech_trie_count'] + df_cleantech_keywords['cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_cleantech_trie_count\n",
    "del df_cleantech_trie_explode\n",
    "del df_cleantech_epo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliance on Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_epo_rel = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/Reliance on Science/cleantech_epo_rel_on_science_abstract.json')\n",
    "df_cleantech_uspto_rel = pd.read_json('/mnt/hdd01/patentsview/Reliance on Science - Cleantech Patents/df_oaid_Cleantech_Y02_individual_works.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_rel = pd.merge(df_cleantech_epo_rel, df_cleantech_uspto_rel, how='outer', left_on='oaid', right_on='oaid')\n",
    "df_cleantech_rel['abstract'] = df_cleantech_rel['abstract_x'].fillna(df_cleantech_rel['abstract_y'])\n",
    "df_cleantech_rel['abstract'] = lemmatize_text(df_cleantech_rel['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_rel['trie'] = df_cleantech_rel['abstract'].apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "df_cleantech_rel['trie'] = df_cleantech_rel['trie'].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_trie_explode = df_cleantech_rel[\"trie\"].explode()\n",
    "df_cleantech_trie_explode = pd.DataFrame(df_cleantech_trie_explode).reset_index()\n",
    "df_cleantech_trie_count = df_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['cleantech_trie_count'] = df_cleantech_keywords['cleantech_trie_count'] + df_cleantech_keywords['cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_cleantech_trie_count\n",
    "del df_cleantech_trie_explode\n",
    "del df_cleantech_epo_rel\n",
    "del df_cleantech_uspto_rel\n",
    "del df_cleantech_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Cleantech Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_uspto = pd.read_json('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/g_uspto_non_cleantech_claims_fulltext.json')\n",
    "# Lemmatize the claim_fulltext\n",
    "df_non_cleantech_uspto['claim_fulltext'] = lemmatize_text(df_non_cleantech_uspto['claim_fulltext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_uspto[\"trie\"] = df_non_cleantech_uspto[\"claim_fulltext\"].apply(lambda x: non_cleantech_trie.search(x, return_nodes=True))\n",
    "df_non_cleantech_uspto[\"trie\"] = df_non_cleantech_uspto[\"trie\"].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_trie_explode = df_non_cleantech_uspto[\"trie\"].explode()\n",
    "df_non_cleantech_trie_explode = pd.DataFrame(df_non_cleantech_trie_explode).reset_index()\n",
    "df_non_cleantech_trie_count = df_non_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='non_cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_non_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['non_cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['non_cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['non_cleantech_trie_count'] = df_cleantech_keywords['non_cleantech_trie_count'] + df_cleantech_keywords['non_cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['non_cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_non_cleantech_trie_count\n",
    "del df_non_cleantech_trie_explode\n",
    "del df_non_cleantech_uspto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_epo = pd.read_json('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/df_epo_non_cleantech_text_data_pivot_claims_cleaned.json')\n",
    "df_non_cleantech_epo['cleaned_claims'] = lemmatize_text(df_non_cleantech_epo['cleaned_claims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_epo[\"trie\"] = df_non_cleantech_epo[\"cleaned_claims\"].apply(lambda x: non_cleantech_trie.search(x, return_nodes=True))\n",
    "df_non_cleantech_epo[\"trie\"] = df_non_cleantech_epo[\"trie\"].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_trie_explode = df_non_cleantech_epo[\"trie\"].explode()\n",
    "df_non_cleantech_trie_explode = pd.DataFrame(df_non_cleantech_trie_explode).reset_index()\n",
    "df_non_cleantech_trie_count = df_non_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='non_cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_non_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['non_cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['non_cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['non_cleantech_trie_count'] = df_cleantech_keywords['non_cleantech_trie_count'] + df_cleantech_keywords['non_cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['non_cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_non_cleantech_trie_count\n",
    "del df_non_cleantech_trie_explode\n",
    "del df_non_cleantech_epo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliance on Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_rel = pd.read_json('/mnt/hdd01/patentsview/Non Cleantech Patents - Classifier Set/df_oaids_non_cleantech.json')\n",
    "df_non_cleantech_rel['abstract'] = lemmatize_text(df_non_cleantech_rel['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_rel[\"trie\"] = df_non_cleantech_rel[\"abstract\"].apply(lambda x: non_cleantech_trie.search(x, return_nodes=True))\n",
    "df_non_cleantech_rel[\"trie\"] = df_non_cleantech_rel[\"trie\"].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_cleantech_trie_explode = df_non_cleantech_rel[\"trie\"].explode()\n",
    "df_non_cleantech_trie_explode = pd.DataFrame(df_non_cleantech_trie_explode).reset_index()\n",
    "df_non_cleantech_trie_count = df_non_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='non_cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_non_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['non_cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['non_cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['non_cleantech_trie_count'] = df_cleantech_keywords['non_cleantech_trie_count'] + df_cleantech_keywords['non_cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['non_cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_non_cleantech_trie_count\n",
    "del df_non_cleantech_trie_explode\n",
    "del df_non_cleantech_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the KL divergence between the two distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_cleantech_trie_count = df_cleantech_keywords['cleantech_trie_count'].sum()\n",
    "sum_non_cleantech_trie_count = df_cleantech_keywords['non_cleantech_trie_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'cleantech_trie_count' is 0, set 'cleantech_trie_count' to 1\n",
    "df_cleantech_keywords.loc[df_cleantech_keywords['cleantech_trie_count'] == 0, 'cleantech_trie_count'] = 1\n",
    "# If 'non_cleantech_trie_count' is 0, set 'non_cleantech_trie_count' to 0.001\n",
    "df_cleantech_keywords.loc[df_cleantech_keywords['non_cleantech_trie_count'] == 0, 'non_cleantech_trie_count'] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count zero values in cleantech_trie_count and non_cleantech_trie_count\n",
    "# num_zero_cleantech_trie_count = df_cleantech_keywords[df_cleantech_keywords['cleantech_trie_count'] == 0].shape[0]\n",
    "# num_zero_non_cleantech_trie_count = df_cleantech_keywords[df_cleantech_keywords['non_cleantech_trie_count'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_keywords['kl_divergence'] = df_cleantech_keywords.apply(lambda x: x['cleantech_trie_count']/sum_cleantech_trie_count * np.log((x['cleantech_trie_count']/sum_cleantech_trie_count)/ (x['non_cleantech_trie_count']/sum_non_cleantech_trie_count)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_keywords.to_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cleantech_keywords_similarity_015_co_occurrence_01_kl_divergence.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
