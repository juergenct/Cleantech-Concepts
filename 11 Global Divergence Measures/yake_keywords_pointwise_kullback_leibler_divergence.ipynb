{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from wordtrie import WordTrie\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_keywords = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cleantech_keywords_similarity_015_co_occurrence_01.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column cleantech_trie_count and non_cleantech_trie_count\n",
    "df_cleantech_keywords['cleantech_trie_count'] = 0\n",
    "df_cleantech_keywords['non_cleantech_trie_count'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build WordTrie\n",
    "def make_wordtrie(keyword_list):\n",
    "    trie = WordTrie()\n",
    "    if keyword_list is None:\n",
    "        return None\n",
    "    i = 0\n",
    "    for keyword in keyword_list:\n",
    "        if isinstance(keyword, str):\n",
    "            trie.add(keyword, i)\n",
    "            i += 1\n",
    "    print(f\"Added {i} keywords to trie\")\n",
    "    return trie\n",
    "\n",
    "# Build WordTrie\n",
    "cleantech_trie = make_wordtrie(df_cleantech_keywords['keyword_yake_lemma'].tolist())\n",
    "non_cleantech_trie = make_wordtrie(df_cleantech_keywords['keyword_yake_lemma'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleantech Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_uspto = pd.read_json('/mnt/hdd01/patentsview/Patentsview - Cleantech Patents/g_patent_claims_cleantech_yake.json')\n",
    "df_cleantech_uspto[\"trie\"] = df_cleantech_uspto[\"claim_fulltext\"].apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "df_cleantech_uspto[\"trie\"] = df_cleantech_uspto[\"trie\"].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_trie_explode = df_cleantech_uspto[\"trie\"].explode()\n",
    "df_cleantech_trie_explode = pd.DataFrame(df_cleantech_trie_explode).reset_index()\n",
    "df_cleantech_trie_count = df_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['cleantech_trie_count'] = df_cleantech_keywords['cleantech_trie_count'] + df_cleantech_keywords['cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_cleantech_trie_count\n",
    "del df_cleantech_trie_explode\n",
    "del df_cleantech_uspto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_epo = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/PATSTAT/cleantech_epo_text_data_pivot_cleaned.json')\n",
    "df_cleantech_epo[\"trie\"] = df_cleantech_epo[\"claim_fulltext\"].apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "df_cleantech_epo[\"trie\"] = df_cleantech_epo[\"trie\"].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_trie_explode = df_cleantech_epo[\"trie\"].explode()\n",
    "df_cleantech_trie_explode = pd.DataFrame(df_cleantech_trie_explode).reset_index()\n",
    "df_cleantech_trie_count = df_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['cleantech_trie_count'] = df_cleantech_keywords['cleantech_trie_count'] + df_cleantech_keywords['cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_cleantech_trie_count\n",
    "del df_cleantech_trie_explode\n",
    "del df_cleantech_epo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliance on Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_epo_rel = pd.read_json('/mnt/hdd01/PATSTAT Working Directory/Reliance on Science/cleantech_epo_rel_on_science_abstract.json')\n",
    "df_cleantech_uspto_rel = pd.read_json('/mnt/hdd01/patentsview/Reliance on Science - Cleantech Patents/df_oaid_Cleantech_Y02_individual_works.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_rel = pd.merge(df_cleantech_epo_rel, df_cleantech_uspto_rel, how='outer', left_on='oaid', right_on='oaid')\n",
    "df_cleantech_rel['abstract'] = df_cleantech_rel['abstract_x'].fillna(df_cleantech_rel['abstract_y'])\n",
    "df_cleantech_rel['trie'] = df_cleantech_rel['abstract'].apply(lambda x: cleantech_trie.search(x, return_nodes=True))\n",
    "df_cleantech_rel['trie'] = df_cleantech_rel['trie'].apply(lambda x: [' '.join(y[0]) for y in x] if len(x) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleantech_trie_explode = df_cleantech_rel[\"trie\"].explode()\n",
    "df_cleantech_trie_explode = pd.DataFrame(df_cleantech_trie_explode).reset_index()\n",
    "df_cleantech_trie_count = df_cleantech_trie_explode.groupby('trie')['index'].count().reset_index(name='cleantech_trie_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df_cleantech_keywords on keyword_yake_lemma and trie, add cleantech_trie_count to cleantech_trie_count in df_cleantech_keywords\n",
    "df_cleantech_keywords = df_cleantech_keywords.merge(df_cleantech_trie_count, how='left', left_on='keyword_yake_lemma', right_on='trie', suffixes=('', '_from_trie_count'))\n",
    "# Fill NaN values with 0 in the new 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords['cleantech_trie_count_from_trie_count'] = df_cleantech_keywords['cleantech_trie_count_from_trie_count'].fillna(0)\n",
    "# Sum the values from the two 'cleantech_trie_count' columns\n",
    "df_cleantech_keywords['cleantech_trie_count'] = df_cleantech_keywords['cleantech_trie_count'] + df_cleantech_keywords['cleantech_trie_count_from_trie_count']\n",
    "# Drop the extra 'cleantech_trie_count_from_trie_count' column\n",
    "df_cleantech_keywords = df_cleantech_keywords.drop(columns=['cleantech_trie_count_from_trie_count', 'trie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all dataframes except df_cleantech_keywords to free up memory\n",
    "del df_cleantech_trie_count\n",
    "del df_cleantech_trie_explode\n",
    "del df_cleantech_epo_rel\n",
    "del df_cleantech_uspto_rel\n",
    "del df_cleantech_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Cleantech Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
