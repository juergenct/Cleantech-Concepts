{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_noun_chunks.json')\n",
    "# Drop columns keyword_yake_pos, keyword_yake_patentsberta_embedding, keyword_yake_climatebert_embedding and keyword_yake_bertforpatents_embedding\n",
    "df_yake_uspto_epo_rel.drop(columns=['keyword_yake_patentsberta_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_bertforpatents_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_titles = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique keywords\n",
    "cleantech_titles = df_yake_cleantech_titles['keyword_yake_lemma'].unique()\n",
    "uspto_epo_rel_keywords = df_yake_uspto_epo_rel['keyword_yake_lemma'].unique()\n",
    "\n",
    "# Initialize co-occurrence matrix\n",
    "co_occurrence_matrix = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'patent_id' column while retaining the 'keyword_yake' column\n",
    "patent_id_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['patent_id'].explode().reset_index()\n",
    "# Put 'US' in front of each patent_id\n",
    "patent_id_exploded['patent_id'] = 'US' + patent_id_exploded['patent_id'].astype(str)\n",
    "# Delete all rows where patent_id contains the string None\n",
    "patent_id_exploded = patent_id_exploded[~patent_id_exploded['patent_id'].str.contains('None')]\n",
    "# Aggregate on 'patent_id', list of keyword_yake_lemma\n",
    "patent_id_exploded = patent_id_exploded.groupby('patent_id')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US10000011</td>\n",
       "      <td>[desired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US10000017</td>\n",
       "      <td>[attachment, inlet opening, mounting apparatus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US10000021</td>\n",
       "      <td>[machining process, predetermined portion, sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US10000025</td>\n",
       "      <td>[damage tolerance, fiber orientation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US10000033</td>\n",
       "      <td>[closure element, eva, substantially flat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patent_id                                 keyword_yake_lemma\n",
       "0  US10000011                                          [desired]\n",
       "1  US10000017  [attachment, inlet opening, mounting apparatus...\n",
       "2  US10000021  [machining process, predetermined portion, sha...\n",
       "3  US10000025              [damage tolerance, fiber orientation]\n",
       "4  US10000033         [closure element, eva, substantially flat]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_id_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'publn_nr' column while retaining the 'keyword_yake' column\n",
    "publn_nr_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['publn_nr'].explode().reset_index()\n",
    "# Put 'EP' in front of each publn_nr\n",
    "publn_nr_exploded['publn_nr'] = 'EP' + publn_nr_exploded['publn_nr'].astype(str)\n",
    "# Delete all rows where publn_nr contains the string None\n",
    "publn_nr_exploded = publn_nr_exploded[~publn_nr_exploded['publn_nr'].str.contains('None')]\n",
    "# Aggregate on 'publn_nr', list all keyword_yake_lemma\n",
    "publn_nr_exploded = publn_nr_exploded.groupby('publn_nr')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP0000085</td>\n",
       "      <td>[benzene, dilute solution, hbr, tributyl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EP0000338</td>\n",
       "      <td>[agar gel, bluetongue virus, charlottesville, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EP0000401</td>\n",
       "      <td>[flock, livelihood, main source, negev, rumina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EP0000715</td>\n",
       "      <td>[high efficiency solar, large area photovoltai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EP0000785</td>\n",
       "      <td>[drainage]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    publn_nr                                 keyword_yake_lemma\n",
       "0  EP0000085          [benzene, dilute solution, hbr, tributyl]\n",
       "1  EP0000338  [agar gel, bluetongue virus, charlottesville, ...\n",
       "2  EP0000401  [flock, livelihood, main source, negev, rumina...\n",
       "3  EP0000715  [high efficiency solar, large area photovoltai...\n",
       "4  EP0000785                                         [drainage]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publn_nr_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'oaid' column while retaining the 'keyword_yake' column\n",
    "oaid_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['oaid'].explode().reset_index()\n",
    "# Put 'REL' in front of each oaid\n",
    "oaid_exploded['oaid'] = 'REL' + oaid_exploded['oaid'].astype(str)\n",
    "# Delete all rows where oaid contains the string None\n",
    "oaid_exploded = oaid_exploded[~oaid_exploded['oaid'].str.contains('None')]\n",
    "# Aggregate on 'oaid', list of 'keyword_yake_lemma'\n",
    "oaid_exploded = oaid_exploded.groupby('oaid')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oaid</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REL100000185</td>\n",
       "      <td>[pain, physiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REL1000054809</td>\n",
       "      <td>[distributed, droop control, electric power sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REL100007697</td>\n",
       "      <td>[latency, millisecond, problematic, rcu, sched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REL100014517</td>\n",
       "      <td>[biochemical and genetic, circular form, idea,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REL1000192467</td>\n",
       "      <td>[arthralgia, headache, july, oval, pregnant wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            oaid                                 keyword_yake_lemma\n",
       "0   REL100000185                                 [pain, physiology]\n",
       "1  REL1000054809  [distributed, droop control, electric power sy...\n",
       "2   REL100007697  [latency, millisecond, problematic, rcu, sched...\n",
       "3   REL100014517  [biochemical and genetic, circular form, idea,...\n",
       "4  REL1000192467  [arthralgia, headache, july, oval, pregnant wo..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oaid_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three exploded dataframes\n",
    "df_keywords_uspto_epo_rel = pd.concat([patent_id_exploded, publn_nr_exploded, oaid_exploded], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>oaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1233684</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[eol, ndfeb, rees]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REL2522817256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449138</th>\n",
       "      <td>US9422915</td>\n",
       "      <td>[adoptive transfer, annual energy, bone marrow...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071794</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[artificial neural network, multitude, neuron,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REL2107994122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119661</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[carrier substrate, mno, superior]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REL2134591935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591048</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[conductive oxide film, dividing groove, photo...</td>\n",
       "      <td>EP2752883</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         patent_id                                 keyword_yake_lemma  \\\n",
       "1233684        NaN                                 [eol, ndfeb, rees]   \n",
       "449138   US9422915  [adoptive transfer, annual energy, bone marrow...   \n",
       "1071794        NaN  [artificial neural network, multitude, neuron,...   \n",
       "1119661        NaN                 [carrier substrate, mno, superior]   \n",
       "591048         NaN  [conductive oxide film, dividing groove, photo...   \n",
       "\n",
       "          publn_nr           oaid  \n",
       "1233684        NaN  REL2522817256  \n",
       "449138         NaN            NaN  \n",
       "1071794        NaN  REL2107994122  \n",
       "1119661        NaN  REL2134591935  \n",
       "591048   EP2752883            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "df_keywords_uspto_epo_rel_exploded = df_keywords_uspto_epo_rel.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_keywords_uspto_epo_rel_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep patent_id, publn_nr and oaid, including duplicates\n",
    "df_yake_uspto_epo_rel_titles_filtered = pd.merge(df_yake_cleantech_titles, df_keywords_uspto_epo_rel_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yake_uspto_epo_rel_titles_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix Single Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 502876/502876 [00:06<00:00, 81298.72it/s]\n",
      "100%|██████████| 176155/176155 [00:01<00:00, 92090.05it/s]\n",
      "100%|██████████| 608091/608091 [00:07<00:00, 79807.15it/s]\n",
      "100%|██████████| 59245/59245 [01:22<00:00, 719.20it/s] \n"
     ]
    }
   ],
   "source": [
    "# Preprocess df_keywords_uspto_epo_rel to create dictionaries for fast lookup\n",
    "patent_id_dict = df_keywords_uspto_epo_rel.groupby('patent_id')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "publn_nr_dict = df_keywords_uspto_epo_rel.groupby('publn_nr')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "oaid_dict = df_keywords_uspto_epo_rel.groupby('oaid')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "\n",
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wastewater treatment          1.000000\n",
       "cod                           0.123746\n",
       "wastewater                    0.100334\n",
       "anaerobic                     0.070234\n",
       "environmental                 0.066890\n",
       "aerobic                       0.063545\n",
       "wastewater treatment plant    0.053512\n",
       "microbial fuel cell           0.053512\n",
       "organic matter                0.050167\n",
       "nutrient                      0.046823\n",
       "hrt                           0.046823\n",
       "phosphorus                    0.046823\n",
       "activated sludge              0.046823\n",
       "mbr                           0.046823\n",
       "treatment plant               0.043478\n",
       "fouling                       0.040134\n",
       "sbr                           0.040134\n",
       "pilot                         0.040134\n",
       "treatment system              0.040134\n",
       "biogas                        0.040134\n",
       "Name: wastewater treatment, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print descending columns for row 'xxx'\n",
    "co_occurrence_matrix.loc['wastewater treatment'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide rows in co-occurence matrix by largest value in row\n",
    "co_occurrence_matrix = co_occurrence_matrix.div(co_occurrence_matrix.max(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_matrix.to_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/co_occurrence_matrix_yake_keywords_cleantech_uspto_epo_rel.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk, df_keywords_uspto_epo_rel, co_occurrence_matrix):\n",
    "    for index, row in chunk.iterrows():\n",
    "        if isinstance(row['patent_id'], str):\n",
    "            for keyword_list in df_keywords_uspto_epo_rel[df_keywords_uspto_epo_rel['patent_id'] == row['patent_id']]['keyword_yake_lemma']:\n",
    "                for keyword in keyword_list:\n",
    "                    co_occurrence_matrix.loc[row['keyword_yake_lemma'], keyword] += 1\n",
    "        elif isinstance(row['publn_nr'], str):\n",
    "            for keyword_list in df_keywords_uspto_epo_rel[df_keywords_uspto_epo_rel['publn_nr'] == row['publn_nr']]['keyword_yake_lemma']:\n",
    "                for keyword in keyword_list:\n",
    "                    co_occurrence_matrix.loc[row['keyword_yake_lemma'], keyword] += 1\n",
    "        elif isinstance(row['oaid'], str):\n",
    "            for keyword_list in df_keywords_uspto_epo_rel[df_keywords_uspto_epo_rel['oaid'] == row['oaid']]['keyword_yake_lemma']:\n",
    "                for keyword in keyword_list:\n",
    "                    co_occurrence_matrix.loc[row['keyword_yake_lemma'], keyword] += 1\n",
    "        else:\n",
    "            print('Error')\n",
    "    return co_occurrence_matrix\n",
    "\n",
    "def main(df_yake_uspto_epo_rel, df_keywords_uspto_epo_rel, co_occurrence_matrix):\n",
    "    num_cores = 6\n",
    "    chunk_size = len(df_yake_uspto_epo_rel) // num_cores\n",
    "\n",
    "    # Create a list of DataFrame chunks\n",
    "    chunks = [df_yake_uspto_epo_rel.iloc[i:i + chunk_size] for i in range(0, df_yake_uspto_epo_rel.shape[0], chunk_size)]\n",
    "\n",
    "    # Set up a multiprocessing Pool\n",
    "    with Pool(num_cores) as pool:\n",
    "        results = list(tqdm(pool.starmap(process_chunk, [(chunk, df_keywords_uspto_epo_rel, co_occurrence_matrix.copy()) for chunk in chunks]), total=len(chunks)))\n",
    "\n",
    "    # Combine the results\n",
    "    for matrix in results:\n",
    "        co_occurrence_matrix += matrix\n",
    "\n",
    "    return co_occurrence_matrix\n",
    "\n",
    "# Call the main function with appropriate arguments\n",
    "co_occurrence_matrix = main(df_yake_uspto_epo_rel, df_keywords_uspto_epo_rel, co_occurrence_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
