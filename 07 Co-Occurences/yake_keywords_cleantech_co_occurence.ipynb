{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "column = 'claim_fulltext' # 'title', 'abstract' or 'claim_fulltext'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Core Cleantech Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yake_cleantech_titles = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks_embeddings.json')\n",
    "# df_yake_cleantech_titles = pd.read_json(\"/home/thiesen/Documents/Cleantech_Concepts/cleantech_keywords_similarity_015_co_occurrence_025_title.json\")\n",
    "df_yake_cleantech_titles = pd.read_json(f\"/home/thiesen/Documents/Cleantech_Concepts/cleantech_keywords_similarity_005_co_occurrence_025_abstract.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Semantic Search enriched Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_similarity = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Similarity Search/df_keyword_titles_cosine_similarity_radius_025_noun_chunks.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode column keywords_bertforpatents\n",
    "df_yake_cleantech_similarity = df_yake_cleantech_similarity.explode('keywords_bertforpatents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new dataframe out of all values in 'keyword_yake_lemma' and 'keywords_bertforpatents' column\n",
    "combined_df = pd.concat([df_yake_cleantech_similarity['keyword_yake_lemma'], df_yake_cleantech_similarity['keywords_bertforpatents']]).drop_duplicates()\n",
    "df_yake_cleantech_titles = pd.DataFrame(combined_df, columns=['keyword_yake_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25304"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_yake_cleantech_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel = pd.read_json(f'/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_{column}_noun_chunks.json')\n",
    "# Drop columns keyword_yake_pos, keyword_yake_patentsberta_embedding, keyword_yake_climatebert_embedding and keyword_yake_bertforpatents_embedding\n",
    "# df_yake_uspto_epo_rel.drop(columns=['keyword_yake_patentsberta_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_bertforpatents_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "      <th>cleantech</th>\n",
       "      <th>keyword_yake_lemma_bertforpatents_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aberrant</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.2693934143, 0.348465234, 0.6860293746, 1.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abundant</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7716676593, 0.1885169297, 0.1095398068, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accumulator</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.504627049, -0.3598301709, 0.3817014694, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accurate</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.7603557110000001, 0.6554374695, -0.5015231...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acidic</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.2268049717, -0.6390919685, 0.3487114012, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword_yake_lemma  cleantech  \\\n",
       "0           aberrant          1   \n",
       "1           abundant          1   \n",
       "2        accumulator          1   \n",
       "3           accurate          1   \n",
       "4             acidic          1   \n",
       "\n",
       "         keyword_yake_lemma_bertforpatents_embedding  \n",
       "0  [0.2693934143, 0.348465234, 0.6860293746, 1.31...  \n",
       "1  [0.7716676593, 0.1885169297, 0.1095398068, -0....  \n",
       "2  [0.504627049, -0.3598301709, 0.3817014694, 0.2...  \n",
       "3  [-0.7603557110000001, 0.6554374695, -0.5015231...  \n",
       "4  [-0.2268049717, -0.6390919685, 0.3487114012, -...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yake_cleantech_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords_yake_claim_fulltext_lemma</th>\n",
       "      <th>abs_frequency</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>oaid</th>\n",
       "      <th>keywords_yake_claim_fulltext_patentsberta_embedding</th>\n",
       "      <th>keywords_yake_claim_fulltext_climatebert_embedding</th>\n",
       "      <th>keywords_yake_claim_fulltext_bertforpatents_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa</td>\n",
       "      <td>35</td>\n",
       "      <td>[5626983, 9949165, 6492046, 5191275, 8758921, ...</td>\n",
       "      <td>[1142043, 3363790, 3041827, 1042828, 2982004]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.009164794300000001, -0.5787734985, -0.3139...</td>\n",
       "      <td>[-0.0193257574, -0.0141516225, 0.0131431855, 0...</td>\n",
       "      <td>[-0.42265179750000004, -0.8338707089, -0.44803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aac</td>\n",
       "      <td>7</td>\n",
       "      <td>[9067969, 7236059, 9524014, 6294352, 6417158, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.1441015601, -0.5350900292, -0.2306492031, ...</td>\n",
       "      <td>[0.025997683400000002, 0.0462871417, 0.0207896...</td>\n",
       "      <td>[0.48455637690000003, -0.2590337992, -0.608433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aar</td>\n",
       "      <td>5</td>\n",
       "      <td>[5986108, 9458069]</td>\n",
       "      <td>[3103867, 2946009, 3385375]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.1567861736, -0.6682188511, -0.2236177772, ...</td>\n",
       "      <td>[-0.0596974939, 0.0217031986, 0.09825296700000...</td>\n",
       "      <td>[-0.3915314078, 0.0007248279, -0.1738779992, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aav</td>\n",
       "      <td>15</td>\n",
       "      <td>[10119125, 9695220, 11104885, 10980896, 717289...</td>\n",
       "      <td>[3060575, 1135468, 3459965, 3062884]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.16056068240000002, -1.0209388733, -0.22905...</td>\n",
       "      <td>[-0.0716600269, -0.0178589281, 0.0750997365, -...</td>\n",
       "      <td>[0.0051265955, -0.9149596095, -0.2827564478000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aav capsid polypeptide</td>\n",
       "      <td>7</td>\n",
       "      <td>[10119125, 9695220, 11104885, 10526584, 9719070]</td>\n",
       "      <td>[3060575, 3459965]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-0.1696463823, -0.8892566562, -0.203945100300...</td>\n",
       "      <td>[-0.0224281326, 0.1100657359, 0.04343590140000...</td>\n",
       "      <td>[-0.46955767270000004, 0.1143041328, -0.460525...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keywords_yake_claim_fulltext_lemma  abs_frequency  \\\n",
       "0                                aaa             35   \n",
       "1                                aac              7   \n",
       "2                                aar              5   \n",
       "3                                aav             15   \n",
       "4             aav capsid polypeptide              7   \n",
       "\n",
       "                                           patent_id  \\\n",
       "0  [5626983, 9949165, 6492046, 5191275, 8758921, ...   \n",
       "1  [9067969, 7236059, 9524014, 6294352, 6417158, ...   \n",
       "2                                 [5986108, 9458069]   \n",
       "3  [10119125, 9695220, 11104885, 10980896, 717289...   \n",
       "4   [10119125, 9695220, 11104885, 10526584, 9719070]   \n",
       "\n",
       "                                        publn_nr oaid  \\\n",
       "0  [1142043, 3363790, 3041827, 1042828, 2982004]   []   \n",
       "1                                             []   []   \n",
       "2                    [3103867, 2946009, 3385375]   []   \n",
       "3           [3060575, 1135468, 3459965, 3062884]   []   \n",
       "4                             [3060575, 3459965]   []   \n",
       "\n",
       "  keywords_yake_claim_fulltext_patentsberta_embedding  \\\n",
       "0  [-0.009164794300000001, -0.5787734985, -0.3139...    \n",
       "1  [-0.1441015601, -0.5350900292, -0.2306492031, ...    \n",
       "2  [-0.1567861736, -0.6682188511, -0.2236177772, ...    \n",
       "3  [-0.16056068240000002, -1.0209388733, -0.22905...    \n",
       "4  [-0.1696463823, -0.8892566562, -0.203945100300...    \n",
       "\n",
       "  keywords_yake_claim_fulltext_climatebert_embedding  \\\n",
       "0  [-0.0193257574, -0.0141516225, 0.0131431855, 0...   \n",
       "1  [0.025997683400000002, 0.0462871417, 0.0207896...   \n",
       "2  [-0.0596974939, 0.0217031986, 0.09825296700000...   \n",
       "3  [-0.0716600269, -0.0178589281, 0.0750997365, -...   \n",
       "4  [-0.0224281326, 0.1100657359, 0.04343590140000...   \n",
       "\n",
       "  keywords_yake_claim_fulltext_bertforpatents_embedding  \n",
       "0  [-0.42265179750000004, -0.8338707089, -0.44803...     \n",
       "1  [0.48455637690000003, -0.2590337992, -0.608433...     \n",
       "2  [-0.3915314078, 0.0007248279, -0.1738779992, 0...     \n",
       "3  [0.0051265955, -0.9149596095, -0.2827564478000...     \n",
       "4  [-0.46955767270000004, 0.1143041328, -0.460525...     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yake_uspto_epo_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique keywords\n",
    "cleantech_titles = df_yake_cleantech_titles['keyword_yake_lemma'].unique()\n",
    "uspto_epo_rel_keywords = df_yake_uspto_epo_rel[f'keywords_yake_{column}_lemma'].unique()\n",
    "\n",
    "# Initialize co-occurrence matrix\n",
    "co_occurrence_matrix_ids = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)\n",
    "co_occurrence_matrix_y02 = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurence by CPC Classification - yields too few results, threshold only leaves 9 unique keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all spaces in list of strings in column 'cpc_class_symbol'\n",
    "df_yake_uspto_epo_rel['cpc_class_symbol'] = df_yake_uspto_epo_rel['cpc_class_symbol'].progress_apply(lambda x: [i.replace(' ', '') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_group' column while retaining the 'keyword_yake_lemma' column\n",
    "cpc_group_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_group'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_group_exploded = cpc_group_exploded[cpc_group_exploded['cpc_group'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_group_exploded = cpc_group_exploded.groupby('cpc_group')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_group_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_class_symbol' column while retaining the 'keyword_yake' column\n",
    "cpc_class_symbol_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_class_symbol'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded[cpc_class_symbol_exploded['cpc_class_symbol'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded.groupby('cpc_class_symbol')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_class_symbol_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on 'cpc_group' and 'cpc_class_symbol', list of keyword_yake_lemma mind that keyword_yake_lemma is list of strings\n",
    "cpc_group_class_symbol_merged = pd.merge(cpc_group_exploded, cpc_class_symbol_exploded, left_on='cpc_group', right_on='cpc_class_symbol', how='outer')\n",
    "# New column cpc - if cpc_group is not NaN, then cpc = cpc_group, else cpc = cpc_class_symbol\n",
    "cpc_group_class_symbol_merged['cpc'] = cpc_group_class_symbol_merged['cpc_group'].fillna(cpc_group_class_symbol_merged['cpc_class_symbol'])\n",
    "# Merge keyword_yake_lemma_x and keyword_yake_lemma_y into one column keyword_yake_lemma\n",
    "cpc_group_class_symbol_merged['keyword_yake_lemma'] = cpc_group_class_symbol_merged.progress_apply(\n",
    "    lambda row: list(set(\n",
    "        (row['keyword_yake_lemma_x'] if isinstance(row['keyword_yake_lemma_x'], list) else []) +\n",
    "        (row['keyword_yake_lemma_y'] if isinstance(row['keyword_yake_lemma_y'], list) else [])\n",
    "    )), axis=1)\n",
    "# Delete columns cpc_group, cpc_class_symbol, keyword_yake_lemma_x and keyword_yake_lemma_y\n",
    "cpc_group_class_symbol_merged.drop(columns=['cpc_group', 'cpc_class_symbol', 'keyword_yake_lemma_x', 'keyword_yake_lemma_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "cpc_group_class_symbol_exploded = cpc_group_class_symbol_merged.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cpc_group_class_symbol_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep cpc column including duplicates\n",
    "cpc_group_class_symbol_filtered = pd.merge(df_yake_cleantech_titles, cpc_group_class_symbol_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = cpc_group_class_symbol_filtered['keyword_yake_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "cpc_group_class_symbol_filtered = cpc_group_class_symbol_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_group_class_symbol_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by CPC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurrence by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'patent_id' column while retaining the 'keyword_yake' column\n",
    "patent_id_exploded = df_yake_uspto_epo_rel.set_index(f'keywords_yake_{column}_lemma')['patent_id'].explode().reset_index()\n",
    "# Put 'US' in front of each patent_id\n",
    "patent_id_exploded['patent_id'] = 'US' + patent_id_exploded['patent_id'].astype(str)\n",
    "# Delete all rows where patent_id contains the string None\n",
    "patent_id_exploded = patent_id_exploded[~patent_id_exploded['patent_id'].str.contains('None')]\n",
    "# Aggregate on 'patent_id', list of keyword_yake_lemma\n",
    "patent_id_exploded = patent_id_exploded.groupby('patent_id')[f'keywords_yake_{column}_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>keywords_yake_claim_fulltext_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US10000011</td>\n",
       "      <td>[comprising forming, desired, support structure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US10000017</td>\n",
       "      <td>[adhesion surface, attachment, mounting appara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US10000021</td>\n",
       "      <td>[machining process, predetermined portion, sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US10000025</td>\n",
       "      <td>[fiber orientation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US10000033</td>\n",
       "      <td>[blend, closure element, substantially flat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patent_id                 keywords_yake_claim_fulltext_lemma\n",
       "0  US10000011   [comprising forming, desired, support structure]\n",
       "1  US10000017  [adhesion surface, attachment, mounting appara...\n",
       "2  US10000021  [machining process, predetermined portion, sha...\n",
       "3  US10000025                                [fiber orientation]\n",
       "4  US10000033       [blend, closure element, substantially flat]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_id_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'publn_nr' column while retaining the 'keyword_yake' column\n",
    "publn_nr_exploded = df_yake_uspto_epo_rel.set_index(f'keywords_yake_{column}_lemma')['publn_nr'].explode().reset_index()\n",
    "# Put 'EP' in front of each publn_nr\n",
    "publn_nr_exploded['publn_nr'] = 'EP' + publn_nr_exploded['publn_nr'].astype(str)\n",
    "# Delete all rows where publn_nr contains the string None\n",
    "publn_nr_exploded = publn_nr_exploded[~publn_nr_exploded['publn_nr'].str.contains('None')]\n",
    "# Aggregate on 'publn_nr', list all keyword_yake_lemma\n",
    "publn_nr_exploded = publn_nr_exploded.groupby('publn_nr')[f'keywords_yake_{column}_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>keywords_yake_claim_fulltext_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP1000004</td>\n",
       "      <td>[organic phase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EP1000028</td>\n",
       "      <td>[acid addition salt, derivative, pharmaceutica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EP100005</td>\n",
       "      <td>[fleece]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EP100007</td>\n",
       "      <td>[air andor oxygen, carrier particle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EP1000085</td>\n",
       "      <td>[enriched, pure]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    publn_nr                 keywords_yake_claim_fulltext_lemma\n",
       "0  EP1000004                                    [organic phase]\n",
       "1  EP1000028  [acid addition salt, derivative, pharmaceutica...\n",
       "2   EP100005                                           [fleece]\n",
       "3   EP100007               [air andor oxygen, carrier particle]\n",
       "4  EP1000085                                   [enriched, pure]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publn_nr_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'oaid' column while retaining the 'keyword_yake' column\n",
    "oaid_exploded = df_yake_uspto_epo_rel.set_index(f'keywords_yake_{column}_lemma')['oaid'].explode().reset_index()\n",
    "# Put 'REL' in front of each oaid\n",
    "oaid_exploded['oaid'] = 'REL' + oaid_exploded['oaid'].astype(str)\n",
    "# Delete all rows where oaid contains the string None\n",
    "oaid_exploded = oaid_exploded[~oaid_exploded['oaid'].str.contains('None')]\n",
    "# Aggregate on 'oaid', list of 'keyword_yake_lemma'\n",
    "oaid_exploded = oaid_exploded.groupby('oaid')[f'keywords_yake_{column}_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oaid</th>\n",
       "      <th>keywords_yake_claim_fulltext_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RELnan</td>\n",
       "      <td>[aaa, aac, aar, aav, aav capsid polypeptide, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     oaid                 keywords_yake_claim_fulltext_lemma\n",
       "0  RELnan  [aaa, aac, aar, aav, aav capsid polypeptide, a..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oaid_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three exploded dataframes\n",
    "# df_keywords_uspto_epo_rel = pd.concat([patent_id_exploded, publn_nr_exploded, oaid_exploded], axis=0).reset_index(drop=True)\n",
    "df_keywords_uspto_epo_rel = pd.concat([patent_id_exploded, publn_nr_exploded], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>keywords_yake_claim_fulltext_lemma</th>\n",
       "      <th>publn_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>228806</th>\n",
       "      <td>US5912919</td>\n",
       "      <td>[early, late, local code sequence, symbol, tra...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156738</th>\n",
       "      <td>US4346151</td>\n",
       "      <td>[mouth]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[controlled variable, waveguide]</td>\n",
       "      <td>EP3345027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234917</th>\n",
       "      <td>US6048643</td>\n",
       "      <td>[lithium intercalation compound]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169273</th>\n",
       "      <td>US4579999</td>\n",
       "      <td>[primary stage, recycle]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patent_id                 keywords_yake_claim_fulltext_lemma  \\\n",
       "228806  US5912919  [early, late, local code sequence, symbol, tra...   \n",
       "156738  US4346151                                            [mouth]   \n",
       "633194        NaN                   [controlled variable, waveguide]   \n",
       "234917  US6048643                   [lithium intercalation compound]   \n",
       "169273  US4579999                           [primary stage, recycle]   \n",
       "\n",
       "         publn_nr  \n",
       "228806        NaN  \n",
       "156738        NaN  \n",
       "633194  EP3345027  \n",
       "234917        NaN  \n",
       "169273        NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "df_keywords_uspto_epo_rel_exploded = df_keywords_uspto_epo_rel.explode(f'keywords_yake_{column}_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677010"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_keywords_uspto_epo_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_keywords_uspto_epo_rel_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep patent_id, publn_nr and oaid, including duplicates\n",
    "df_yake_uspto_epo_rel_titles_filtered = pd.merge(df_yake_cleantech_titles, df_keywords_uspto_epo_rel_exploded, how='inner', left_on='keyword_yake_lemma', right_on=f'keywords_yake_{column}_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = df_yake_uspto_epo_rel_titles_filtered[f'keywords_yake_{column}_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "df_yake_uspto_epo_rel_titles_filtered = df_yake_uspto_epo_rel_titles_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yake_uspto_epo_rel_titles_filtered[f'keywords_yake_{column}_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 28791/503825 [00:00<00:04, 97440.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 503825/503825 [00:06<00:00, 74582.10it/s]\n",
      " 91%|█████████ | 156991/173185 [00:03<00:00, 48685.01it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3233480/1923308411.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Preprocess df_keywords_uspto_epo_rel to create dictionaries for fast lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpatent_id_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_keywords_uspto_epo_rel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'patent_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'keywords_yake_{column}_lemma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpubln_nr_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_keywords_uspto_epo_rel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'publn_nr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'keywords_yake_{column}_lemma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moaid_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_keywords_uspto_epo_rel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oaid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'keywords_yake_{column}_lemma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Function to update co-occurrence matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"series\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_apply_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"series_examples\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m                 \u001b[0;31m# try again, with .apply acting as a filtering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m                 \u001b[0;31m# operation, by excluding the grouping column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1811\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0mSeries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \"\"\"\n\u001b[0;32m-> 1815\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_groupwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnot_indexed_same\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0mnot_indexed_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# This calls DataSplitter.__iter__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mzipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzipped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;31m# Pinning name is needed for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;31m#  test_group_apply_once_per_group,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;31m#  test_inconsistent_return_type, test_set_group_name,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;31m# fastpath equivalent to `sdata.iloc[slice_obj]`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"groupby\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Cleantech_Concepts/venv/lib64/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   6167\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6170\u001b[0m             \u001b[0;31m# For subclasses using _metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6171\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6172\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6173\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preprocess df_keywords_uspto_epo_rel to create dictionaries for fast lookup\n",
    "patent_id_dict = df_keywords_uspto_epo_rel.groupby('patent_id')[f'keywords_yake_{column}_lemma'].progress_apply(list).to_dict()\n",
    "publn_nr_dict = df_keywords_uspto_epo_rel.groupby('publn_nr')[f'keywords_yake_{column}_lemma'].progress_apply(list).to_dict()\n",
    "# oaid_dict = df_keywords_uspto_epo_rel.groupby('oaid')[f'keywords_yake_{column}_lemma'].progress_apply(list).to_dict()\n",
    "\n",
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wastewater treatment    211\n",
       "mfc                       6\n",
       "microbial fuel cell       6\n",
       "treatment system          5\n",
       "anaerobic                 5\n",
       "treatment plant           5\n",
       "matter                    4\n",
       "throughput                4\n",
       "anammox                   4\n",
       "algae                     3\n",
       "constructed               3\n",
       "bod                       3\n",
       "biofilm                   3\n",
       "environmental             3\n",
       "effluent                  3\n",
       "wwtp                      3\n",
       "cod                       3\n",
       "floc                      3\n",
       "treatment process         3\n",
       "wetland                   3\n",
       "Name: wastewater treatment, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print descending columns for row 'xxx'2\n",
    "co_occurrence_matrix_ids.loc['wastewater treatment'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows with only zeros\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.loc[(co_occurrence_matrix_ids!=0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide rows in co-occurence matrix by largest value in row\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.div(co_occurrence_matrix_ids.max(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_matrix_ids.to_csv(f'/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Co-Occurrence Analysis/co_occurrence_matrix_yake_keywords_cleantech_uspto_epo_rel_ids_semantic_similarity_{column}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
