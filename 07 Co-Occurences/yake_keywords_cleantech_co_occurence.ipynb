{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Core Cleantech Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_titles = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks_embeddings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Semantic Search enriched Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_similarity = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Similarity Search/df_keyword_titles_cosine_similarity_radius_025_noun_chunks.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode column keywords_bertforpatents\n",
    "df_yake_cleantech_similarity = df_yake_cleantech_similarity.explode('keywords_bertforpatents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new dataframe out of all values in 'keyword_yake_lemma' and 'keywords_bertforpatents' column\n",
    "combined_df = pd.concat([df_yake_cleantech_similarity['keyword_yake_lemma'], df_yake_cleantech_similarity['keywords_bertforpatents']]).drop_duplicates()\n",
    "df_yake_cleantech_titles = pd.DataFrame(combined_df, columns=['keyword_yake_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25304"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_yake_cleantech_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_noun_chunks.json')\n",
    "# Drop columns keyword_yake_pos, keyword_yake_patentsberta_embedding, keyword_yake_climatebert_embedding and keyword_yake_bertforpatents_embedding\n",
    "df_yake_uspto_epo_rel.drop(columns=['keyword_yake_patentsberta_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_bertforpatents_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique keywords\n",
    "cleantech_titles = df_yake_cleantech_titles['keyword_yake_lemma'].unique()\n",
    "uspto_epo_rel_keywords = df_yake_uspto_epo_rel['keyword_yake_lemma'].unique()\n",
    "\n",
    "# Initialize co-occurrence matrix\n",
    "co_occurrence_matrix_ids = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)\n",
    "co_occurrence_matrix_y02 = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurence by CPC Classification - yields too few results, threshold only leaves 9 unique keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all spaces in list of strings in column 'cpc_class_symbol'\n",
    "df_yake_uspto_epo_rel['cpc_class_symbol'] = df_yake_uspto_epo_rel['cpc_class_symbol'].progress_apply(lambda x: [i.replace(' ', '') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_group' column while retaining the 'keyword_yake_lemma' column\n",
    "cpc_group_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_group'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_group_exploded = cpc_group_exploded[cpc_group_exploded['cpc_group'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_group_exploded = cpc_group_exploded.groupby('cpc_group')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_group_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_class_symbol' column while retaining the 'keyword_yake' column\n",
    "cpc_class_symbol_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_class_symbol'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded[cpc_class_symbol_exploded['cpc_class_symbol'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded.groupby('cpc_class_symbol')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_class_symbol_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on 'cpc_group' and 'cpc_class_symbol', list of keyword_yake_lemma mind that keyword_yake_lemma is list of strings\n",
    "cpc_group_class_symbol_merged = pd.merge(cpc_group_exploded, cpc_class_symbol_exploded, left_on='cpc_group', right_on='cpc_class_symbol', how='outer')\n",
    "# New column cpc - if cpc_group is not NaN, then cpc = cpc_group, else cpc = cpc_class_symbol\n",
    "cpc_group_class_symbol_merged['cpc'] = cpc_group_class_symbol_merged['cpc_group'].fillna(cpc_group_class_symbol_merged['cpc_class_symbol'])\n",
    "# Merge keyword_yake_lemma_x and keyword_yake_lemma_y into one column keyword_yake_lemma\n",
    "cpc_group_class_symbol_merged['keyword_yake_lemma'] = cpc_group_class_symbol_merged.progress_apply(\n",
    "    lambda row: list(set(\n",
    "        (row['keyword_yake_lemma_x'] if isinstance(row['keyword_yake_lemma_x'], list) else []) +\n",
    "        (row['keyword_yake_lemma_y'] if isinstance(row['keyword_yake_lemma_y'], list) else [])\n",
    "    )), axis=1)\n",
    "# Delete columns cpc_group, cpc_class_symbol, keyword_yake_lemma_x and keyword_yake_lemma_y\n",
    "cpc_group_class_symbol_merged.drop(columns=['cpc_group', 'cpc_class_symbol', 'keyword_yake_lemma_x', 'keyword_yake_lemma_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "cpc_group_class_symbol_exploded = cpc_group_class_symbol_merged.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cpc_group_class_symbol_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep cpc column including duplicates\n",
    "cpc_group_class_symbol_filtered = pd.merge(df_yake_cleantech_titles, cpc_group_class_symbol_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = cpc_group_class_symbol_filtered['keyword_yake_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "cpc_group_class_symbol_filtered = cpc_group_class_symbol_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_group_class_symbol_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by CPC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurrence by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'patent_id' column while retaining the 'keyword_yake' column\n",
    "patent_id_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['patent_id'].explode().reset_index()\n",
    "# Put 'US' in front of each patent_id\n",
    "patent_id_exploded['patent_id'] = 'US' + patent_id_exploded['patent_id'].astype(str)\n",
    "# Delete all rows where patent_id contains the string None\n",
    "patent_id_exploded = patent_id_exploded[~patent_id_exploded['patent_id'].str.contains('None')]\n",
    "# Aggregate on 'patent_id', list of keyword_yake_lemma\n",
    "patent_id_exploded = patent_id_exploded.groupby('patent_id')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_id_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'publn_nr' column while retaining the 'keyword_yake' column\n",
    "publn_nr_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['publn_nr'].explode().reset_index()\n",
    "# Put 'EP' in front of each publn_nr\n",
    "publn_nr_exploded['publn_nr'] = 'EP' + publn_nr_exploded['publn_nr'].astype(str)\n",
    "# Delete all rows where publn_nr contains the string None\n",
    "publn_nr_exploded = publn_nr_exploded[~publn_nr_exploded['publn_nr'].str.contains('None')]\n",
    "# Aggregate on 'publn_nr', list all keyword_yake_lemma\n",
    "publn_nr_exploded = publn_nr_exploded.groupby('publn_nr')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publn_nr_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'oaid' column while retaining the 'keyword_yake' column\n",
    "oaid_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['oaid'].explode().reset_index()\n",
    "# Put 'REL' in front of each oaid\n",
    "oaid_exploded['oaid'] = 'REL' + oaid_exploded['oaid'].astype(str)\n",
    "# Delete all rows where oaid contains the string None\n",
    "oaid_exploded = oaid_exploded[~oaid_exploded['oaid'].str.contains('None')]\n",
    "# Aggregate on 'oaid', list of 'keyword_yake_lemma'\n",
    "oaid_exploded = oaid_exploded.groupby('oaid')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oaid_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three exploded dataframes\n",
    "df_keywords_uspto_epo_rel = pd.concat([patent_id_exploded, publn_nr_exploded, oaid_exploded], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "df_keywords_uspto_epo_rel_exploded = df_keywords_uspto_epo_rel.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_keywords_uspto_epo_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_keywords_uspto_epo_rel_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep patent_id, publn_nr and oaid, including duplicates\n",
    "df_yake_uspto_epo_rel_titles_filtered = pd.merge(df_yake_cleantech_titles, df_keywords_uspto_epo_rel_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = df_yake_uspto_epo_rel_titles_filtered['keyword_yake_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "df_yake_uspto_epo_rel_titles_filtered = df_yake_uspto_epo_rel_titles_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel_titles_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess df_keywords_uspto_epo_rel to create dictionaries for fast lookup\n",
    "patent_id_dict = df_keywords_uspto_epo_rel.groupby('patent_id')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "publn_nr_dict = df_keywords_uspto_epo_rel.groupby('publn_nr')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "oaid_dict = df_keywords_uspto_epo_rel.groupby('oaid')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "\n",
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print descending columns for row 'xxx'\n",
    "co_occurrence_matrix_ids.loc['wastewater treatment'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows with only zeros\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.loc[(co_occurrence_matrix_ids!=0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide rows in co-occurence matrix by largest value in row\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.div(co_occurrence_matrix_ids.max(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_matrix_ids.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Co-Occurence Analysis/co_occurrence_matrix_yake_keywords_cleantech_uspto_epo_rel_ids_semantic_similarity_02.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
