{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_noun_chunks.json')\n",
    "# Drop columns keyword_yake_pos, keyword_yake_patentsberta_embedding, keyword_yake_climatebert_embedding and keyword_yake_bertforpatents_embedding\n",
    "df_yake_uspto_epo_rel.drop(columns=['keyword_yake_patentsberta_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_bertforpatents_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_titles = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks_embeddings.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique keywords\n",
    "cleantech_titles = df_yake_cleantech_titles['keyword_yake_lemma'].unique()\n",
    "uspto_epo_rel_keywords = df_yake_uspto_epo_rel['keyword_yake_lemma'].unique()\n",
    "\n",
    "# Initialize co-occurrence matrix\n",
    "co_occurrence_matrix_ids = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)\n",
    "co_occurrence_matrix_y02 = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurence by CPC Classification - yields too few results, threshold only leaves 9 unique keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151044/151044 [00:00<00:00, 713238.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Delete all spaces in list of strings in column 'cpc_class_symbol'\n",
    "df_yake_uspto_epo_rel['cpc_class_symbol'] = df_yake_uspto_epo_rel['cpc_class_symbol'].progress_apply(lambda x: [i.replace(' ', '') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "      <th>yake_conf_score</th>\n",
       "      <th>abs_frequency</th>\n",
       "      <th>patent_id</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>oaid</th>\n",
       "      <th>cpc_group</th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27961</th>\n",
       "      <td>control box</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>29</td>\n",
       "      <td>[10027148, 10767578, 10152038, 11374428, 56441...</td>\n",
       "      <td>[2506374, 3147732, 2011189, 2662501, 3434899, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Y02B20/00, Y02E10/50, Y02B70/10, Y02E10/20, Y...</td>\n",
       "      <td>[Y02T10/7072, Y02T10/70, Y02E60/10, Y02T90/167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15113</th>\n",
       "      <td>bound antibody</td>\n",
       "      <td>0.176998</td>\n",
       "      <td>5</td>\n",
       "      <td>[10080793, 8012699, 9140702, 9645148, 6596481]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[2083818919, 1965943147]</td>\n",
       "      <td>[Y02A50/30]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60684</th>\n",
       "      <td>heat transfer block</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>7</td>\n",
       "      <td>[10288318, 4200472, 4051891, 6688292, 7921648]</td>\n",
       "      <td>[1111217, 2706318]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Y02E10/52, Y02E60/14, Y02B10/20, Y02T10/12, Y...</td>\n",
       "      <td>[Y02T10/12, Y02B30/12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25809</th>\n",
       "      <td>compostable</td>\n",
       "      <td>0.097497</td>\n",
       "      <td>6</td>\n",
       "      <td>[11414533, 10625925, 8292543]</td>\n",
       "      <td>[153282, 2651779, 3380325]</td>\n",
       "      <td>[2941288009]</td>\n",
       "      <td>[Y02W90/10, Y02W30/40, Y02W30/30, Y02W30/80]</td>\n",
       "      <td>[Y02W90/10, Y02A40/20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70664</th>\n",
       "      <td>inside wall surface</td>\n",
       "      <td>0.047997</td>\n",
       "      <td>12</td>\n",
       "      <td>[4385915, 10411312, 10982587, 8852768, 1076754...</td>\n",
       "      <td>[134038, 2426223]</td>\n",
       "      <td>[2063242315]</td>\n",
       "      <td>[Y02E60/32, Y02T10/12, Y02P70/50, Y02E60/10, Y...</td>\n",
       "      <td>[Y02P10/25, Y02P10/32, Y02T10/12, Y02E20/34]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        keyword_yake_lemma  yake_conf_score  abs_frequency  \\\n",
       "27961          control box         0.022067             29   \n",
       "15113       bound antibody         0.176998              5   \n",
       "60684  heat transfer block         0.005127              7   \n",
       "25809          compostable         0.097497              6   \n",
       "70664  inside wall surface         0.047997             12   \n",
       "\n",
       "                                               patent_id  \\\n",
       "27961  [10027148, 10767578, 10152038, 11374428, 56441...   \n",
       "15113     [10080793, 8012699, 9140702, 9645148, 6596481]   \n",
       "60684     [10288318, 4200472, 4051891, 6688292, 7921648]   \n",
       "25809                      [11414533, 10625925, 8292543]   \n",
       "70664  [4385915, 10411312, 10982587, 8852768, 1076754...   \n",
       "\n",
       "                                                publn_nr  \\\n",
       "27961  [2506374, 3147732, 2011189, 2662501, 3434899, ...   \n",
       "15113                                                 []   \n",
       "60684                                 [1111217, 2706318]   \n",
       "25809                         [153282, 2651779, 3380325]   \n",
       "70664                                  [134038, 2426223]   \n",
       "\n",
       "                           oaid  \\\n",
       "27961                        []   \n",
       "15113  [2083818919, 1965943147]   \n",
       "60684                        []   \n",
       "25809              [2941288009]   \n",
       "70664              [2063242315]   \n",
       "\n",
       "                                               cpc_group  \\\n",
       "27961  [Y02B20/00, Y02E10/50, Y02B70/10, Y02E10/20, Y...   \n",
       "15113                                        [Y02A50/30]   \n",
       "60684  [Y02E10/52, Y02E60/14, Y02B10/20, Y02T10/12, Y...   \n",
       "25809       [Y02W90/10, Y02W30/40, Y02W30/30, Y02W30/80]   \n",
       "70664  [Y02E60/32, Y02T10/12, Y02P70/50, Y02E60/10, Y...   \n",
       "\n",
       "                                        cpc_class_symbol  \n",
       "27961  [Y02T10/7072, Y02T10/70, Y02E60/10, Y02T90/167...  \n",
       "15113                                                 []  \n",
       "60684                             [Y02T10/12, Y02B30/12]  \n",
       "25809                             [Y02W90/10, Y02A40/20]  \n",
       "70664       [Y02P10/25, Y02P10/32, Y02T10/12, Y02E20/34]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yake_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_group' column while retaining the 'keyword_yake_lemma' column\n",
    "cpc_group_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_group'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_group_exploded = cpc_group_exploded[cpc_group_exploded['cpc_group'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_group_exploded = cpc_group_exploded.groupby('cpc_group')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpc_group</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Y02P30/20</td>\n",
       "      <td>[abm, absence, absolute, absolute ethanol, abs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Y02A50/2351</td>\n",
       "      <td>[activated carbon, activated carbon powder, ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Y02P10/134</td>\n",
       "      <td>[acceptor, account, acid dew, acid gas, acid g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Y02A30/27</td>\n",
       "      <td>[absolute temperature, absorb, absorbed, absor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Y02T10/00</td>\n",
       "      <td>[air delivery system, catalytic article, catal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cpc_group                                 keyword_yake_lemma\n",
       "204    Y02P30/20  [abm, absence, absolute, absolute ethanol, abs...\n",
       "63   Y02A50/2351  [activated carbon, activated carbon powder, ac...\n",
       "177   Y02P10/134  [acceptor, account, acid dew, acid gas, acid g...\n",
       "34     Y02A30/27  [absolute temperature, absorb, absorbed, absor...\n",
       "254    Y02T10/00  [air delivery system, catalytic article, catal..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc_group_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_class_symbol' column while retaining the 'keyword_yake' column\n",
    "cpc_class_symbol_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_class_symbol'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded[cpc_class_symbol_exploded['cpc_class_symbol'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded.groupby('cpc_class_symbol')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cpc_class_symbol</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Y02E60/36</td>\n",
       "      <td>[abo, absorbent polymer, absorber, absorbing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Y02P20/129</td>\n",
       "      <td>[absorber, absorbing liquid, absorption appara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Y02E10/46</td>\n",
       "      <td>[absorber, absorber element, absorber liquid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Y02P10/143</td>\n",
       "      <td>[additional hydrogen, additional oxygen, air c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Y02B10/40</td>\n",
       "      <td>[absorber liquid, absorption refrigerating mac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cpc_class_symbol                                 keyword_yake_lemma\n",
       "190        Y02E60/36  [abo, absorbent polymer, absorber, absorbing a...\n",
       "203       Y02P20/129  [absorber, absorbing liquid, absorption appara...\n",
       "134        Y02E10/46  [absorber, absorber element, absorber liquid, ...\n",
       "196       Y02P10/143  [additional hydrogen, additional oxygen, air c...\n",
       "69         Y02B10/40  [absorber liquid, absorption refrigerating mac..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc_class_symbol_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 358/358 [00:00<00:00, 4514.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# Merge the two dataframes on 'cpc_group' and 'cpc_class_symbol', list of keyword_yake_lemma mind that keyword_yake_lemma is list of strings\n",
    "cpc_group_class_symbol_merged = pd.merge(cpc_group_exploded, cpc_class_symbol_exploded, left_on='cpc_group', right_on='cpc_class_symbol', how='outer')\n",
    "# New column cpc - if cpc_group is not NaN, then cpc = cpc_group, else cpc = cpc_class_symbol\n",
    "cpc_group_class_symbol_merged['cpc'] = cpc_group_class_symbol_merged['cpc_group'].fillna(cpc_group_class_symbol_merged['cpc_class_symbol'])\n",
    "# Merge keyword_yake_lemma_x and keyword_yake_lemma_y into one column keyword_yake_lemma\n",
    "cpc_group_class_symbol_merged['keyword_yake_lemma'] = cpc_group_class_symbol_merged.progress_apply(\n",
    "    lambda row: list(set(\n",
    "        (row['keyword_yake_lemma_x'] if isinstance(row['keyword_yake_lemma_x'], list) else []) +\n",
    "        (row['keyword_yake_lemma_y'] if isinstance(row['keyword_yake_lemma_y'], list) else [])\n",
    "    )), axis=1)\n",
    "# Delete columns cpc_group, cpc_class_symbol, keyword_yake_lemma_x and keyword_yake_lemma_y\n",
    "cpc_group_class_symbol_merged.drop(columns=['cpc_group', 'cpc_class_symbol', 'keyword_yake_lemma_x', 'keyword_yake_lemma_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "cpc_group_class_symbol_exploded = cpc_group_class_symbol_merged.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cpc_group_class_symbol_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep cpc column including duplicates\n",
    "cpc_group_class_symbol_filtered = pd.merge(df_yake_cleantech_titles, cpc_group_class_symbol_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = cpc_group_class_symbol_filtered['keyword_yake_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "cpc_group_class_symbol_filtered = cpc_group_class_symbol_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc_group_class_symbol_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by CPC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurrence by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'patent_id' column while retaining the 'keyword_yake' column\n",
    "patent_id_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['patent_id'].explode().reset_index()\n",
    "# Put 'US' in front of each patent_id\n",
    "patent_id_exploded['patent_id'] = 'US' + patent_id_exploded['patent_id'].astype(str)\n",
    "# Delete all rows where patent_id contains the string None\n",
    "patent_id_exploded = patent_id_exploded[~patent_id_exploded['patent_id'].str.contains('None')]\n",
    "# Aggregate on 'patent_id', list of keyword_yake_lemma\n",
    "patent_id_exploded = patent_id_exploded.groupby('patent_id')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_id_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'publn_nr' column while retaining the 'keyword_yake' column\n",
    "publn_nr_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['publn_nr'].explode().reset_index()\n",
    "# Put 'EP' in front of each publn_nr\n",
    "publn_nr_exploded['publn_nr'] = 'EP' + publn_nr_exploded['publn_nr'].astype(str)\n",
    "# Delete all rows where publn_nr contains the string None\n",
    "publn_nr_exploded = publn_nr_exploded[~publn_nr_exploded['publn_nr'].str.contains('None')]\n",
    "# Aggregate on 'publn_nr', list all keyword_yake_lemma\n",
    "publn_nr_exploded = publn_nr_exploded.groupby('publn_nr')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publn_nr_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'oaid' column while retaining the 'keyword_yake' column\n",
    "oaid_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['oaid'].explode().reset_index()\n",
    "# Put 'REL' in front of each oaid\n",
    "oaid_exploded['oaid'] = 'REL' + oaid_exploded['oaid'].astype(str)\n",
    "# Delete all rows where oaid contains the string None\n",
    "oaid_exploded = oaid_exploded[~oaid_exploded['oaid'].str.contains('None')]\n",
    "# Aggregate on 'oaid', list of 'keyword_yake_lemma'\n",
    "oaid_exploded = oaid_exploded.groupby('oaid')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oaid_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three exploded dataframes\n",
    "df_keywords_uspto_epo_rel = pd.concat([patent_id_exploded, publn_nr_exploded, oaid_exploded], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "df_keywords_uspto_epo_rel_exploded = df_keywords_uspto_epo_rel.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_keywords_uspto_epo_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_keywords_uspto_epo_rel_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep patent_id, publn_nr and oaid, including duplicates\n",
    "df_yake_uspto_epo_rel_titles_filtered = pd.merge(df_yake_cleantech_titles, df_keywords_uspto_epo_rel_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = df_yake_uspto_epo_rel_titles_filtered['keyword_yake_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "df_yake_uspto_epo_rel_titles_filtered = df_yake_uspto_epo_rel_titles_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel_titles_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess df_keywords_uspto_epo_rel to create dictionaries for fast lookup\n",
    "patent_id_dict = df_keywords_uspto_epo_rel.groupby('patent_id')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "publn_nr_dict = df_keywords_uspto_epo_rel.groupby('publn_nr')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "oaid_dict = df_keywords_uspto_epo_rel.groupby('oaid')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "\n",
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print descending columns for row 'xxx'\n",
    "co_occurrence_matrix_ids.loc['wastewater treatment'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows with only zeros\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.loc[(co_occurrence_matrix_ids!=0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide rows in co-occurence matrix by largest value in row\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.div(co_occurrence_matrix_ids.max(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_matrix_ids.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Co-Occurence Analysis/co_occurrence_matrix_yake_keywords_cleantech_uspto_epo_rel_ids.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
