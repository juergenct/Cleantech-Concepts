{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Core Cleantech Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_titles = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/cpc_yake_keywords_list_noun_chunks_embeddings.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Semantic Search enriched Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_cleantech_similarity = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Similarity Search/df_keyword_titles_cosine_similarity_radius_025_noun_chunks.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode column keywords_bertforpatents\n",
    "df_yake_cleantech_similarity = df_yake_cleantech_similarity.explode('keywords_bertforpatents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new dataframe out of all values in 'keyword_yake_lemma' and 'keywords_bertforpatents' column\n",
    "combined_df = pd.concat([df_yake_cleantech_similarity['keyword_yake_lemma'], df_yake_cleantech_similarity['keywords_bertforpatents']]).drop_duplicates()\n",
    "df_yake_cleantech_titles = pd.DataFrame(combined_df, columns=['keyword_yake_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25304"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_yake_cleantech_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data for Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel = pd.read_json('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/df_keywords_list_agg_uspto_epo_rel_embeddings_noun_chunks.json')\n",
    "# Drop columns keyword_yake_pos, keyword_yake_patentsberta_embedding, keyword_yake_climatebert_embedding and keyword_yake_bertforpatents_embedding\n",
    "df_yake_uspto_epo_rel.drop(columns=['keyword_yake_patentsberta_embedding', 'keyword_yake_climatebert_embedding', 'keyword_yake_bertforpatents_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique keywords\n",
    "cleantech_titles = df_yake_cleantech_titles['keyword_yake_lemma'].unique()\n",
    "uspto_epo_rel_keywords = df_yake_uspto_epo_rel['keyword_yake_lemma'].unique()\n",
    "\n",
    "# Initialize co-occurrence matrix\n",
    "co_occurrence_matrix_ids = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)\n",
    "co_occurrence_matrix_y02 = pd.DataFrame(0, index=cleantech_titles, columns=uspto_epo_rel_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurence by CPC Classification - yields too few results, threshold only leaves 9 unique keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all spaces in list of strings in column 'cpc_class_symbol'\n",
    "df_yake_uspto_epo_rel['cpc_class_symbol'] = df_yake_uspto_epo_rel['cpc_class_symbol'].progress_apply(lambda x: [i.replace(' ', '') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yake_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_group' column while retaining the 'keyword_yake_lemma' column\n",
    "cpc_group_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_group'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_group_exploded = cpc_group_exploded[cpc_group_exploded['cpc_group'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_group_exploded = cpc_group_exploded.groupby('cpc_group')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_group_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'cpc_class_symbol' column while retaining the 'keyword_yake' column\n",
    "cpc_class_symbol_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['cpc_class_symbol'].explode().reset_index()\n",
    "# Delete all rows where cpc_group is of type Float\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded[cpc_class_symbol_exploded['cpc_class_symbol'].apply(lambda x: isinstance(x, str))]\n",
    "# Aggregate on 'cpc_group', list of keyword_yake_lemma\n",
    "cpc_class_symbol_exploded = cpc_class_symbol_exploded.groupby('cpc_class_symbol')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_class_symbol_exploded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on 'cpc_group' and 'cpc_class_symbol', list of keyword_yake_lemma mind that keyword_yake_lemma is list of strings\n",
    "cpc_group_class_symbol_merged = pd.merge(cpc_group_exploded, cpc_class_symbol_exploded, left_on='cpc_group', right_on='cpc_class_symbol', how='outer')\n",
    "# New column cpc - if cpc_group is not NaN, then cpc = cpc_group, else cpc = cpc_class_symbol\n",
    "cpc_group_class_symbol_merged['cpc'] = cpc_group_class_symbol_merged['cpc_group'].fillna(cpc_group_class_symbol_merged['cpc_class_symbol'])\n",
    "# Merge keyword_yake_lemma_x and keyword_yake_lemma_y into one column keyword_yake_lemma\n",
    "cpc_group_class_symbol_merged['keyword_yake_lemma'] = cpc_group_class_symbol_merged.progress_apply(\n",
    "    lambda row: list(set(\n",
    "        (row['keyword_yake_lemma_x'] if isinstance(row['keyword_yake_lemma_x'], list) else []) +\n",
    "        (row['keyword_yake_lemma_y'] if isinstance(row['keyword_yake_lemma_y'], list) else [])\n",
    "    )), axis=1)\n",
    "# Delete columns cpc_group, cpc_class_symbol, keyword_yake_lemma_x and keyword_yake_lemma_y\n",
    "cpc_group_class_symbol_merged.drop(columns=['cpc_group', 'cpc_class_symbol', 'keyword_yake_lemma_x', 'keyword_yake_lemma_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "cpc_group_class_symbol_exploded = cpc_group_class_symbol_merged.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge cpc_group_class_symbol_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep cpc column including duplicates\n",
    "cpc_group_class_symbol_filtered = pd.merge(df_yake_cleantech_titles, cpc_group_class_symbol_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = cpc_group_class_symbol_filtered['keyword_yake_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "cpc_group_class_symbol_filtered = cpc_group_class_symbol_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpc_group_class_symbol_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by CPC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Occurrence by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'patent_id' column while retaining the 'keyword_yake' column\n",
    "patent_id_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['patent_id'].explode().reset_index()\n",
    "# Put 'US' in front of each patent_id\n",
    "patent_id_exploded['patent_id'] = 'US' + patent_id_exploded['patent_id'].astype(str)\n",
    "# Delete all rows where patent_id contains the string None\n",
    "patent_id_exploded = patent_id_exploded[~patent_id_exploded['patent_id'].str.contains('None')]\n",
    "# Aggregate on 'patent_id', list of keyword_yake_lemma\n",
    "patent_id_exploded = patent_id_exploded.groupby('patent_id')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US10000011</td>\n",
       "      <td>[comprising forming, desired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US10000017</td>\n",
       "      <td>[adhesion surface, attachment, mounting appara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US10000021</td>\n",
       "      <td>[machining process, predetermined portion, sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US10000025</td>\n",
       "      <td>[fiber orientation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US10000033</td>\n",
       "      <td>[closure element, substantially flat]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patent_id                                 keyword_yake_lemma\n",
       "0  US10000011                      [comprising forming, desired]\n",
       "1  US10000017  [adhesion surface, attachment, mounting appara...\n",
       "2  US10000021  [machining process, predetermined portion, sha...\n",
       "3  US10000025                                [fiber orientation]\n",
       "4  US10000033              [closure element, substantially flat]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_id_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'publn_nr' column while retaining the 'keyword_yake' column\n",
    "publn_nr_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['publn_nr'].explode().reset_index()\n",
    "# Put 'EP' in front of each publn_nr\n",
    "publn_nr_exploded['publn_nr'] = 'EP' + publn_nr_exploded['publn_nr'].astype(str)\n",
    "# Delete all rows where publn_nr contains the string None\n",
    "publn_nr_exploded = publn_nr_exploded[~publn_nr_exploded['publn_nr'].str.contains('None')]\n",
    "# Aggregate on 'publn_nr', list all keyword_yake_lemma\n",
    "publn_nr_exploded = publn_nr_exploded.groupby('publn_nr')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP1000004</td>\n",
       "      <td>[organic phase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EP1000028</td>\n",
       "      <td>[acid addition salt, pharmaceutically acceptab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EP100005</td>\n",
       "      <td>[fleece]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EP100007</td>\n",
       "      <td>[air andor oxygen, carrier particle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EP1000085</td>\n",
       "      <td>[adrenergic, enriched]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    publn_nr                                 keyword_yake_lemma\n",
       "0  EP1000004                                    [organic phase]\n",
       "1  EP1000028  [acid addition salt, pharmaceutically acceptab...\n",
       "2   EP100005                                           [fleece]\n",
       "3   EP100007               [air andor oxygen, carrier particle]\n",
       "4  EP1000085                             [adrenergic, enriched]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publn_nr_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the 'oaid' column while retaining the 'keyword_yake' column\n",
    "oaid_exploded = df_yake_uspto_epo_rel.set_index('keyword_yake_lemma')['oaid'].explode().reset_index()\n",
    "# Put 'REL' in front of each oaid\n",
    "oaid_exploded['oaid'] = 'REL' + oaid_exploded['oaid'].astype(str)\n",
    "# Delete all rows where oaid contains the string None\n",
    "oaid_exploded = oaid_exploded[~oaid_exploded['oaid'].str.contains('None')]\n",
    "# Aggregate on 'oaid', list of 'keyword_yake_lemma'\n",
    "oaid_exploded = oaid_exploded.groupby('oaid')['keyword_yake_lemma'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oaid</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REL100000185</td>\n",
       "      <td>[pain, physiology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REL1000054809</td>\n",
       "      <td>[distributed, droop control, electric power sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REL100007697</td>\n",
       "      <td>[latency, problematic, rcu, scheduling, small ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REL100014517</td>\n",
       "      <td>[biochemical and genetic, circular form, idea,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REL1000192467</td>\n",
       "      <td>[arthralgia, headache, july, oval, pregnant wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            oaid                                 keyword_yake_lemma\n",
       "0   REL100000185                                 [pain, physiology]\n",
       "1  REL1000054809  [distributed, droop control, electric power sy...\n",
       "2   REL100007697  [latency, problematic, rcu, scheduling, small ...\n",
       "3   REL100014517  [biochemical and genetic, circular form, idea,...\n",
       "4  REL1000192467  [arthralgia, headache, july, oval, pregnant wo..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oaid_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the three exploded dataframes\n",
    "df_keywords_uspto_epo_rel = pd.concat([patent_id_exploded, publn_nr_exploded, oaid_exploded], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>keyword_yake_lemma</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>oaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372442</th>\n",
       "      <td>US8540485</td>\n",
       "      <td>[desired, guidance, rotor system, supporting, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109447</th>\n",
       "      <td>US11193853</td>\n",
       "      <td>[damaged, sensing element]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[bacillus thuringiensis subsp, icp, insecticid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REL1947086922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338993</th>\n",
       "      <td>US8066480</td>\n",
       "      <td>[drive motor speed, electronic control, pitch ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478117</th>\n",
       "      <td>US9773292</td>\n",
       "      <td>[scheduler, submission queue]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         patent_id                                 keyword_yake_lemma  \\\n",
       "372442   US8540485  [desired, guidance, rotor system, supporting, ...   \n",
       "109447  US11193853                         [damaged, sensing element]   \n",
       "727497         NaN  [bacillus thuringiensis subsp, icp, insecticid...   \n",
       "338993   US8066480  [drive motor speed, electronic control, pitch ...   \n",
       "478117   US9773292                      [scheduler, submission queue]   \n",
       "\n",
       "       publn_nr           oaid  \n",
       "372442      NaN            NaN  \n",
       "109447      NaN            NaN  \n",
       "727497      NaN  REL1947086922  \n",
       "338993      NaN            NaN  \n",
       "478117      NaN            NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_uspto_epo_rel.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'keyword_yake_lemma' column\n",
    "df_keywords_uspto_epo_rel_exploded = df_keywords_uspto_epo_rel.explode('keyword_yake_lemma').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268280"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_keywords_uspto_epo_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_keywords_uspto_epo_rel_exploded with df_yake_cleantech_titles on 'keyword_yake_lemma'and keep patent_id, publn_nr and oaid, including duplicates\n",
    "df_yake_uspto_epo_rel_titles_filtered = pd.merge(df_yake_cleantech_titles, df_keywords_uspto_epo_rel_exploded, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows corresponding to 'keyword_yake_lemma' when keyword_yake_lemma occurs less than x times\n",
    "co_occurrence_threshold = 100\n",
    "co_occurrence = df_yake_uspto_epo_rel_titles_filtered['keyword_yake_lemma'].value_counts()\n",
    "co_occurrence = co_occurrence[co_occurrence > co_occurrence_threshold]\n",
    "co_occurrence = co_occurrence.reset_index()\n",
    "co_occurrence.columns = ['keyword_yake_lemma', 'count']\n",
    "df_yake_uspto_epo_rel_titles_filtered = df_yake_uspto_epo_rel_titles_filtered.merge(co_occurrence, how='inner', left_on='keyword_yake_lemma', right_on='keyword_yake_lemma', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yake_uspto_epo_rel_titles_filtered['keyword_yake_lemma'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurence Matrix by IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499317/499317 [00:05<00:00, 84362.45it/s]\n",
      "100%|██████████| 171474/171474 [00:01<00:00, 93990.56it/s]\n",
      "100%|██████████| 597489/597489 [00:06<00:00, 85746.31it/s]\n",
      "100%|██████████| 38700/38700 [00:11<00:00, 3479.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess df_keywords_uspto_epo_rel to create dictionaries for fast lookup\n",
    "patent_id_dict = df_keywords_uspto_epo_rel.groupby('patent_id')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "publn_nr_dict = df_keywords_uspto_epo_rel.groupby('publn_nr')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "oaid_dict = df_keywords_uspto_epo_rel.groupby('oaid')['keyword_yake_lemma'].progress_apply(list).to_dict()\n",
    "\n",
    "# Function to update co-occurrence matrix\n",
    "def update_co_occurrence(row):\n",
    "    if isinstance(row['patent_id'], str) and row['patent_id'] in patent_id_dict:\n",
    "        keyword_lists = patent_id_dict[row['patent_id']]\n",
    "    elif isinstance(row['publn_nr'], str) and row['publn_nr'] in publn_nr_dict:\n",
    "        keyword_lists = publn_nr_dict[row['publn_nr']]\n",
    "    elif isinstance(row['oaid'], str) and row['oaid'] in oaid_dict:\n",
    "        keyword_lists = oaid_dict[row['oaid']]\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    for keyword_list in keyword_lists:\n",
    "        for keyword in keyword_list:\n",
    "            co_occurrence_matrix_ids.at[row['keyword_yake_lemma'], keyword] += 1\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "for index, row in tqdm(df_yake_uspto_epo_rel_titles_filtered.iterrows(), total=len(df_yake_uspto_epo_rel_titles_filtered)):\n",
    "    update_co_occurrence(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wastewater treatment     186\n",
       "treatment system           6\n",
       "microbial fuel cell        6\n",
       "anaerobic                  6\n",
       "mfc                        6\n",
       "treatment plant            5\n",
       "algae                      4\n",
       "aerobic                    4\n",
       "biofilm                    3\n",
       "wwtp                       3\n",
       "activated                  3\n",
       "biogas                     3\n",
       "pressurized gas            3\n",
       "digestion                  3\n",
       "biological wastewater      3\n",
       "mbr                        3\n",
       "wetland                    3\n",
       "constructed                3\n",
       "environmental              3\n",
       "floc                       3\n",
       "Name: wastewater treatment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print descending columns for row 'xxx'\n",
    "co_occurrence_matrix_ids.loc['wastewater treatment'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows with only zeros\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.loc[(co_occurrence_matrix_ids!=0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide rows in co-occurence matrix by largest value in row\n",
    "co_occurrence_matrix_ids = co_occurrence_matrix_ids.div(co_occurrence_matrix_ids.max(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence_matrix_ids.to_csv('/mnt/hdd01/patentsview/Similarity Search - CPC Classification and Claims/Co-Occurrence Analysis/co_occurrence_matrix_yake_keywords_cleantech_uspto_epo_rel_ids_semantic_similarity_02.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
